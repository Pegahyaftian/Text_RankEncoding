{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 6321 Assignment 1: Predictive Compression\n",
    "\n",
    "This assignment asks you to do text compression using machine learning. Specifically, you're going to train machine learning models to predict \"the next symbol\" in a string and, by making \"the next symbol\" more predictable, you will make the string easier to compress. Like most real-world problems, a lot of the work is in understanding the problem setup.\n",
    "\n",
    "To understand the idea, ask yourself: if you were given 5 symbols, `impor`, what would you guess for the *next symbol*? If those 5 symbols are enough to predict that the next symbol is a `t`, then there's no need to actually store the code for `t`! \n",
    "\n",
    "<img src=\"img/shannon.png\" style=\"float:left; margin-right:8px\"/>\n",
    "\n",
    "In fact, [Claude Shannon](https://en.wikipedia.org/wiki/Claude_Shannon#/media/File:ClaudeShannon_MFO3807.jpg), the developer of information entropy, performed this exact experiment by asking his human colleagues to \"guess the next letter\" from context. Read page 1 of Peter Fenwick's [*Symbol Ranking Text Compression with Shannon Recodings*](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.50.4148&rep=rep1&type=pdf). Question 3 of this assignment will ask you to implement compression using Shannon's \"second method\" (symbol rank encoding), where the classifier you trained in Question 2 plays the role of the \"guesser\". The better the guess, the more compressible the ranks are.\n",
    "\n",
    "To understand how symbol rank encoding works, **consider a toy example**. Assume the symbol alphabet is $\\{a,b,c\\}$, for simplicity. A \"guesser\" receives one \"previous symbol\" and must guess a probabily for each possible \"next symbol.\" The example guesser shown below (at left) believes that strings like `abcabc` are most probable whereas strings like `aaaaaa` or `bbbbbb` are improbable. The steps below depict how these probabilities are used to rank-encode the example string `[a,b,c,b,c]` as sequence of numbers `[0,0,0,1,0]`.\n",
    "\n",
    "<img src=\"img/rank-encoding-1.png\" width=750px/>\n",
    "\n",
    "Notice that, in the rank encoding, the first `b` was encoded as 0, but the second `b` was encoded as 1 because the toy guesser expected `a` to be more probable, based on the previous symbol (i.e., the context).\n",
    "\n",
    "When symbols are predicted correctly (or approximately-correctly), a rank-encoding is more compressible by a Huffman encoder because the new representation (rank ordinals) has lower information entropy than the original (ASCII ordinals)!\n",
    "\n",
    "<img src=\"img/rank-encoding-2.png\" width=520px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The assignment is very much like a lab, in that many steps build on each other. The main differences are:\n",
    "1. the assignment combines multiple machine learning concepts, rather than one theme;\n",
    "2. the assignment becomes more open-ended as questions progress, with fewer \"guardrails\";\n",
    "3. the assignment will be more carefully graded, including code quality; and\n",
    "4. where <span style=\"color:#080;font-weight:bold\">specified</span>, you must add comments to your code.\n",
    "\n",
    "The goal of the assignment is to exposes you to:\n",
    "* Building a machine learning system for a real practical purpose (compression).\n",
    "* Designing custom scikit-learn data transformers (converting dicts &amp; strings to features) and all the software engineering challenges there,\n",
    "* Doing model selection over a pipeline with configurable stages (hyperparameter search).\n",
    "* Using a loss function (classification performance) that differs from the ultimate measure of success (compression ratio).\n",
    "\n",
    "**Grading.** There are 5 questions: Q1 (20 marks), Q2 (30 marks), Q3 (25 marks), Q4 (30 marks), Q5 (5 BONUS marks).\n",
    "\n",
    "**Rules for academic integrity:**\n",
    "* Like labs, students are encouraged to ask conceptual questions of TAs and of other students, and can answer each others' *conceptual* questions.\n",
    "* Unlike labs, students are *not* allowed to post example code in a public forum, even if the code is wrong; code and pseudocode can only be shared with TAs when requesting help.\n",
    "* Never ask for, or offer, code snippets for the assignment to your fellow students. Doing so is forbidden, and is a major violation of academic integrity, both of the person who shared the code and the person who accepted the code. Violations of academic integrity will be reported to the Dean's Office. Violators risk their academic standing.\n",
    "* *Never* post your assignment on the internet, including Github, even after the course completes; see above rule.\n",
    "\n",
    "**Read the statement below and insert your name:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I, Pegah Yaftian, hereby confirm that I have understood and at all times adhered to the above rules of academic integrity, and to the academic code of conduct at Concordia University. All completed steps of this submitted assignment are my own independent work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advice:**\n",
    "* *Invest in plotting.* Plotting is super important for ML and for data sciences generally. So, put in the time to learn how to make plots properly.\n",
    "* *Set random_state whenever applicable.* Some steps of the assignment involve randomness, usually when calling scikit-learn functions. In order to make your assignment reproducible, you must set the *random_state* to some constant (e.g. 0) whenever applicable.\n",
    "* *Save your notebook frequently.* Although Jupyter notebooks are mostly reliable, it is possible to encounter an erroneous state, where the most recent changes cannot be saved to disk by the notebook's own save functionality.\n",
    "\n",
    "**Run the code cell below** to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.pipeline\n",
    "import sklearn.feature_selection\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.preprocessing\n",
    "import sklearn.utils\n",
    "import sklearn.utils.estimator_checks\n",
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "# Download huffman.py from github before importing\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/soxofaan/dahuffman/' +\n",
    "                           '7bbc964cee6947545ee4dfb4456c96c9be44cebc/dahuffman/' +\n",
    "                           'huffmancodec.py', 'huffman.py')\n",
    "import huffman\n",
    "\n",
    "# Matplotlib might complain if lots of figures are generated; suppress that warning.\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q1 &mdash; Download and compress text files [20 marks total]\n",
    "\n",
    "This question asks you to download some example Python source code, and then compress it using a Python implementation of Huffman encoding. The specific source code you'll compress will be from scikit-learn's Github repository.\n",
    "\n",
    "The reason to download a copy of scikit-learn's source code is *not* to install or to run it. In fact, you do not even need to extract the zip file. The *only* reason for downloading it to have some example Python source code.\n",
    "\n",
    "Later on in the assignment, you will try to improve the compression using machine learning. In other words, you will be using your already-installed scikit-learn package to compress the separate scikit-learn source code that you just downloaded!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q1a &mdash; Download Python code to use for training and testing [10 marks]*\n",
    "\n",
    "**Download some example Python source code.** Specifically, download the source code to scikit-learn version 0.24.1 as a zip file. To do this, visit the scikit-learn github repository, find the tag `0.24.1`, click \"browse files\" and find the URL for `0.24.1.zip`.\n",
    "\n",
    "You should do the download *procedurally*, by writing code in the code cell below, so that any time your notebook is run it will automatically download the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "URL= 'https://github.com/scikit-learn/scikit-learn/archive/0.24.1.zip'\n",
    "# Download the file from the URL\n",
    "filename,header = urlretrieve(URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement *read_textfiles***. Use the *zipfile* package that is built in to Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_textfiles(zip_file: str, name_filter, maxbytes=None):\n",
    "    \"\"\"\n",
    "    Open a zip file and returns two lists:\n",
    "      names: list of file names for which name_filter(name) returned True\n",
    "      texts: list of bytes objects with corresponding file contents.\n",
    "    If maxbytes is specified, only the first maxbytes of each file will be read.\n",
    "    \"\"\"\n",
    "\n",
    "    # Your implementation here.\n",
    "    with zipfile.ZipFile(zip_file,\"r\") as myzip:\n",
    "        \n",
    "        f_names=[]\n",
    "        file_names= myzip.namelist()\n",
    "        for names in file_names:\n",
    "            for x in name_filter:\n",
    "                if names.endswith(x):\n",
    "                    f_names.append(names) \n",
    "        content=[]\n",
    "        for name in f_names:\n",
    "            with myzip.open(name) as f:\n",
    "                txt = f.read()\n",
    "                content.append((txt[:maxbytes])) \n",
    "    return f_names,content\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Load a training and test set.** Create two global variables, each referring to what we'll call a \"text list\" (a list of *bytes* objects). One variable should refer to a list of *bytes* objects containing source code from training files, and likewise the other should refer to data from testing files.\n",
    "* training set is the three files ending with `/kernels.py`, `/_logistic.py`, and `/_gaussian_mixture.py`\n",
    "* testing set is the two file ending with `/_ridge.py` and `/naive_bayes.py`\n",
    "\n",
    "To keep reasonably training fast, load only the first 10,000 bytes of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['scikit-learn-0.24.1/sklearn/gaussian_process/kernels.py',\n",
       "  'scikit-learn-0.24.1/sklearn/linear_model/_logistic.py',\n",
       "  'scikit-learn-0.24.1/sklearn/mixture/_gaussian_mixture.py'],\n",
       " ['scikit-learn-0.24.1/sklearn/linear_model/_ridge.py',\n",
       "  'scikit-learn-0.24.1/sklearn/naive_bayes.py'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "name_filter_trn = ['/kernels.py','/_logistic.py','/_gaussian_mixture.py']\n",
    "names_trn,texts_trn = read_textfiles(filename, name_filter_trn, maxbytes=10000)\n",
    "\n",
    "name_filter_tst = ['/_ridge.py','/naive_bayes.py']\n",
    "names_tst,texts_tst = read_textfiles(filename, name_filter_tst,maxbytes=10000)\n",
    "\n",
    "\n",
    "names_trn, names_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement *preview_textlist*** and **run it on your training and test sets** so that you and the TA can see excerpts of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"\"\"Kernels for Gaussian process regression and classification.\\n\\nThe kernels in this module allow ker'\n",
      "b'\"\"\"\\nLogistic Regression\\n\"\"\"\\n\\n# Author: Gael Varoquaux <gael.varoquaux@normalesup.org>\\n#         Fabi'\n",
      "b'\"\"\"Gaussian Mixture Model.\"\"\"\\n\\n# Author: Wei Xue <xuewei4d@gmail.com>\\n# Modified by Thierry Guillemo'\n",
      "b'\"\"\"\\nRidge regression\\n\"\"\"\\n\\n# Author: Mathieu Blondel <mathieu@mblondel.org>\\n#         Reuben Fletcher'\n",
      "b'# -*- coding: utf-8 -*-\\n\\n\"\"\"\\nThe :mod:`sklearn.naive_bayes` module implements Naive Bayes algorithms'\n"
     ]
    }
   ],
   "source": [
    "def check_is_textlist(x):\n",
    "    if not isinstance(x, list) or \\\n",
    "       not all(isinstance(text, bytes) for text in x):\n",
    "        raise ValueError(\"Expected textlist\")\n",
    "\n",
    "def preview_textlist(x: list, maxitems=5, maxbytes=100):\n",
    "    \"\"\"\n",
    "    Prints some example excerpts from the entries of x.    \n",
    "    Up to maxitems entries are shown, and for each up to\n",
    "    maxbytes are printed in the preview.\n",
    "    \n",
    "    For example:\n",
    "       >>> x = [b'good', b'luck on', b'the assignment']\n",
    "       >>> preview_textlist(x, maxfiles=2, maxbytes=4)\n",
    "       Contains 3 file(s) totalling 25 bytes:\n",
    "       \n",
    "       b'good'\n",
    "\n",
    "       b'luck'\n",
    "    \"\"\"\n",
    "    check_is_textlist(x)\n",
    "    # Your implementation here\n",
    "    for item in x[:maxitems]:\n",
    "        item=item[:maxbytes]\n",
    "        print(item)\n",
    "            \n",
    "\n",
    "# Call your implementation here\n",
    "preview_textlist(texts_trn, maxitems=5, maxbytes=100)\n",
    "preview_textlist(texts_tst, maxitems=5, maxbytes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a complete alphabet.** When training on categorical features or targets, whether they be ASCII symbols like $\\{a,b,c\\}$ or job titles like $\\{teacher,police,doctor\\}$, it is important to not assume that your training set contains all the symbols (categories) for which you need to make predictions. Why? Because training sets are often split up in arbitrary ways, such as for cross-validation; if one of those chunks is missing a category that you need to make predictions from, then it will cause your ML system to raise annoying errors at test time or at cross-validation time, often after lots of CPU time invested. So, use the code cell below to define an *ALPHABET* global variable for later use.\n",
    "\n",
    "Ensure *ALPHABET*'s symbols appear in order of increasing ordinal value. Explicitly add the NULL byte with ordinal value 0 (`\\x00`), since it will be used to mean \"no symbol\" later on. Print *ALPHABET*'s length and contents, like below but with `?` replaced with values:\n",
    "```\n",
    "??? symbols\n",
    "b'\\x00??????????????????????....'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 symbols\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'\\x00\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHABET=b'\\x00'+b'\\n'+bytes(range(32,127))\n",
    "print(len(ALPHABET),\"symbols\")\n",
    "ALPHABET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q1b &mdash; Define a scikit-learn Transformer to compress text files [10 marks]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a *HuffmanEncoder* transformer class.** Define a custom scikit-learn transformer, so that the following code would run:\n",
    "```python\n",
    ">>> x = [b'aaaa', b'bbb']\n",
    ">>> huff = HuffmanEncoder()\n",
    ">>> huff.fit(x).transform(x)   # Success!\n",
    "[b'\\n', b'\\xfe']\n",
    ">>> huff.fit_transform(x)      # Same, provided by TransformerMixin!\n",
    "[b'\\n', b'\\xfe']\n",
    ">>> z = [b'c']                 # New text not in training set\n",
    ">>> huff.transform(z)          # Uh-oh, unrecognized symbol 'c' (ord 99)\n",
    "KeyError: 99\n",
    ">>> HuffmanEncoder(alphabet=b'abc').fit(x).transform(z)  # Force 'c' into alphabet\n",
    "[b'\\x94']\n",
    "\n",
    "```\n",
    "And as for all steps in this assignment it's important to do basic sanity checks of arguments:\n",
    "```python\n",
    ">>> huff = HuffmanEncoder()\n",
    ">>> huff.transform(x)          # Checks that fit() has been called\n",
    "NotFittedError: This HuffmanEncoder instance is not fitted yet.\n",
    ">>> huff.fit(x, y=[1,2,3])     # Checks that y arg not used\n",
    "ValueError: Expected None\n",
    ">>> huff.fit(b'abc')           # Checks that x is a textlist\n",
    "ValueError: Expected textlist\n",
    "\n",
    "```\n",
    "\n",
    "To do this correctly, you're going to want to:\n",
    "1. Look at the *a1-intro.ipynb* notebook and learn how the downloaded *huffman* Python module could help make your class very easy to implement. All the pieces you need are there, including \"dealing with unrecognized symbols.\"\n",
    "2. Look at examples of how other scikit-learn transformers have been implemented, such as the [source code for *StandardScaler*](https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/preprocessing/_data.py#L564), and understand why it inherits both [*BaseEstimator*](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) and [*TransformerMixin*](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html). \n",
    "3. Understand scikit-learn conventions around \"[estimated attributes](https://scikit-learn.org/stable/developers/develop.html#estimated-attributes)\" to signify that *fit* has been called, the meaning of \"trailing underscores\", the fact that estimator attributes are \"cloned\" from the original prototype argument before *fit* (important for making hyperparameter search work), and how [*check_is_fitted*](https://scikit-learn.org/stable/modules/generated/sklearn.utils.validation.check_is_fitted.html) automatically raises *NotFittedError* for you.\n",
    "\n",
    "The documentation on [developing scikit-learn estimators](https://scikit-learn.org/stable/developers/develop.html) may also help, although it discusses many features you do not need for this particular exercise. Your *HuffmanEncode* class transforms a *list* object to a new *list* object, rather than an $\\mathbf{X}$ matrix. As such, it will not pass the checks by *sklearn.utils.estimator_checks.check_estimator*, but that is OK! \n",
    "\n",
    "<span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_none(y):\n",
    "    if y is not None:\n",
    "        raise ValueError(\"Expected None\")\n",
    "\n",
    "def check_is_List(X):\n",
    "    if not isinstance(X, list):\n",
    "        raise ValueError(\"Expected textlist\")\n",
    "        \n",
    "\n",
    "# Your class definition here. You can also import whatever you need.\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HuffmanEncoder(BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__( self,alphabet=None ):\n",
    "        self.alphabet=alphabet\n",
    "      \n",
    "    \n",
    "    def fit( self, X, y = None ):\n",
    "        \n",
    "        \n",
    "        \n",
    "        check_is_none(y)\n",
    "        check_is_List(X)\n",
    "        \n",
    "        X_con=b''.join(X)                                        \n",
    "        if self.alphabet==None:                                    #Alphabet is defined to force unseen data to huffman encoder\n",
    "            codec = huffman.HuffmanCodec.from_data(X_con)\n",
    "            self.codec=codec \n",
    "\n",
    "        else:\n",
    "            \n",
    "            freqs_min = Counter({c: 1e-6 for c in self.alphabet })\n",
    "            freqs_data=Counter(X_con)\n",
    "            freqs=freqs_data| freqs_min \n",
    "            codec = huffman.HuffmanCodec.from_frequencies(freqs, concat=bytes)\n",
    "            self.codec=codec\n",
    "        self.is_fitted_=True\n",
    "        return self\n",
    "    \n",
    "    #Method that describes transormer\n",
    "    def transform( self, X, y = None ):\n",
    "        \n",
    "        check_is_fitted(self)\n",
    "        encod=[]\n",
    "        i=range(len(X))\n",
    "        for num in i:\n",
    "            encoded = self.codec.encode(X[num]) \n",
    "            encod.append(encoded)\n",
    "            self.encod=encod\n",
    "        return self.encod\n",
    "\n",
    "    #Method that describes fit_transorm\n",
    "    def fit_transform(self,X,y=None):\n",
    "        self.fit(X,y)   \n",
    "        self.transform(X,y)\n",
    "        return self.encod\n",
    "    \n",
    "    \n",
    "    def score(self,X,y=None):\n",
    "        encode=self.fit_transform(X,y)\n",
    "        self.encode=encode\n",
    "        encoded_length= np.sum([len(x) for x in encode])\n",
    "        X_length= np.sum([len(x) for x in X])\n",
    "        score=X_length/ encoded_length\n",
    "        return score\n",
    "   \n",
    "    def inverse_transform(self,X,y=None):\n",
    "        inverse=[]\n",
    "        i=range(len(X))\n",
    "        for num in i:\n",
    "            decoded = self.codec.decode(X[num]) \n",
    "            inverse.append(decoded)\n",
    "            self.inverse=inverse            \n",
    "        return self.inverse\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'aaaa', b'bbb']---> [b'\\xf0', b'T']\n",
      "[b'c']---> [b'\\x94']\n",
      "[inverse]---> [b'aaaa', b'bbb']\n"
     ]
    }
   ],
   "source": [
    "#Comparing with examples\n",
    "X = [b'aaaa', b'bbb']\n",
    "z=[b'c']\n",
    "huff=HuffmanEncoder()\n",
    "train=huff.fit_transform(X)\n",
    "test=HuffmanEncoder(alphabet=b'abc').fit(X).transform(z)\n",
    "print(\"[b'aaaa', b'bbb']--->\",train)\n",
    "print(\"[b'c']--->\",test)\n",
    "inverse=huff.inverse_transform(train)\n",
    "print(\"[inverse]--->\",inverse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Huffman-encoded versions of your datasets.** The output should be similar to your earlier preview, except the total bytes should be smaller and the data should mostly be non-printable byte codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xadZ\\xb1\\x85hwFM\\xd6\\x06\\xa9E$Y\\x8e\\xa7\\x0b{\\xa4Ho \\xd2,\\xdb\\xacv\\x87\\xd1\\xc1\\x16n\\xcf\\xb1\\xfc\\xdb\\xb2\\xceu[\\xf5\\x11\\xa1\\xdd\\x199\\xeb\\xfb\\xf2O\\x96\\xa2\\x91\\xeb\\x03\\x1d\\xb1\\xd1\\x1a\\x1d\\xd1\\x9b\\xbd\\xe5\\x9e\\xee\\x86{\\xc8W2\\xec\\xa2\\xbf\\xbfk\\xbe\\xc7\\\\\\x1d\\x9f\\xb6\\xf3\\x07=\\xda\\x19\\x19\\x87\\xf7\\xebZO\\xac\\xc7hk\\t\\xeb6'\n",
      "b'\\xadZ\\xb4\\xf1\\xb5\\xb9d\\xbf\\x9f^sy\\x06\\x91f\\xdd\\x9dj\\xd5\\xa73)\\x83O\\xef\\xb0Tj\\x94h\\xdci\\x01l\\x01LS\\xcfL\\x07(\\xd1\\xcb\"\\x02\\xd8\\x02\\x98\\xa7\\x9e`{`\\xf2\\x07\\xa5I\\xe5\\xb0r\\x13L\\xca\\xaa\\xab\\x8dq\\x83\\x98\\xeb&\\xed\\x01\\xbc\\xacP\\x98\\x0b\\x8c\\x0e\\x0ec\\xa7\\x97\\xbb\\xf14\\xcc\\xaa\\xaa\\xa6\\x08\\xf7\\x9f\\x1d\\xa05\\xaaA\\x1e'\n",
      "b'\\xadZ\\xb5R\\x8aH\\xb3\\x1dq\\xbey\\xff\\xa45\\xc6\\xf6\\xa3G-j\\xd5\\xa73)\\x83O\\xef\\xb0Td\\xcbr\\xe0i\\xd4\\xc0s\\xe9\\xdc}\\xcf:P`yy\\x19\\x1c\\xbe\\xdb\\xc14\\xcc\\xb8\\xde\\xd4f\\xec\\xed\\x0e\\rv\\xab~t\\x02\\xbbT\\xa9\\xc8\\xc7\\xbe[\\xe9\\x80\\xfd\\xf9\\xd0\\n\\xf2\\xf2\\xa7#\\x1e\\xf9o\\xcb\\x8f`\\x10`yy\\x19\\x1c\\xbe\\xdb\\xc14\\xcc'\n"
     ]
    }
   ],
   "source": [
    "huff=HuffmanEncoder(ALPHABET)\n",
    "huff.fit(texts_trn)\n",
    "train=huff.transform(texts_trn)\n",
    "preview_textlist(train, maxitems=5, maxbytes=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xadZ\\xb4\\xf9\\xcc\\xd1\\xcbP\\xdeA\\xa4Y\\xb7gZ\\xb5i\\xcc\\xca`\\xd3\\xfb\\xec\\x15\\x1co\\x1f\\xbf;K\\x80\\x87n\\xd1\\xa3L\\x07\\x91\\xfb\\xf3\\xb4\\x98\\x1f0Gn\\xd1\\xa3\\x96\\xc1\\xc8M3*\\xaa\\xaf9\\xb4\\xe0\\xef\\\\k\\x1e\\xff\\xdb\\xf4\\r\\x12X\\xbf\\x9e\\xa6\\x006\\x9c\\x1d\\xec\\xb7\\x0f\\x7f\\xed\\xfa\\x1e\\xd8\\xbf\\x9e\\x98\\x1e^FG/\\xb6\\xf0M3*\\xaa\\xae5'\n",
      "b\"2\\x9a'5\\xf6\\xd4g\\xbc\\xaa4\\xfe\\xe3y\\xd7M\\x13\\x9b9\\xd6\\xadZu[\\xf5\\xa9\\xe5\\xa8\\xa9\\x80d {\\x01\\xd9{\\x19\\x91\\xbc`\\xc5},\\x03|\\xb5\\x14\\x8f\\\\\\xf8q\\xef\\x9b\\xdf\\x92a\\xc6dk\\x80\\xa2\\xbe\\x93\\x03\\xe5`\\xcf\\xef\\xf0\\xa5j\\xb7\\xe9l\\xe05*O\\xa1#%\\xb4#\\xd8\\x0e\\xe7\\xbc\\x9f7\\xf7\\xda\\x82p`\\xb6\\x86\\xdd`\\xe7\\x1d|\"\n"
     ]
    }
   ],
   "source": [
    "test=huff.transform(texts_tst)\n",
    "preview_textlist(test, maxitems=5, maxbytes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement a *score* method** on your *HuffmanEncode* class definition. Do so by editing the earlier code cell. A *HuffmanEncode* object should score a text list by returning the [compression ratio](https://en.wikipedia.org/wiki/Data_compression_ratio) achieved. For example:\n",
    "```python\n",
    ">>> huff.score(x)   # If hypothetically a 3.5x compression ratio\n",
    "3.5\n",
    "```\n",
    "In the code cell below, print the compression ratio of your training and (separately) testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set compression ratio: 1.7361111111111112\n",
      "Test set compression ratio i: 1.734304543877905\n"
     ]
    }
   ],
   "source": [
    "# Print the compression ratios of your training and testing sets here\n",
    "print(\"Training set compression ratio: %s\" %huff.score(texts_trn))\n",
    "print(\"Test set compression ratio i: %s\" %huff.score(texts_tst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement an *inverse_transform* method** on your *HuffmanEncode* class definition in the earlier code cell. Just like for other scikit-learn transformers, this should \"undo\" the transformation (i.e., decompress a compressed textlist). Once you have added that function, use it in the code cell below to **assert that it decompresses your training and (separately) testing data correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct!\n",
      "correct!\n"
     ]
    }
   ],
   "source": [
    "# Your assertions here\n",
    " \n",
    "#assertion for test set\n",
    "assert isinstance (huff.inverse_transform(train), list), \"Output is supposed to be a list!\"\n",
    "assert len(texts_trn)==len(huff.inverse_transform(train)),\"Output size does not match the input size!\"\n",
    "for i in range(len(huff.inverse_transform(train))):\n",
    "    assert isinstance (huff.inverse_transform(train)[i], bytes),\"Output is supposed to be byte\"\n",
    "assert huff.inverse_transform(train)==texts_trn\n",
    "print(\"correct!\")\n",
    "\n",
    "#assertion for train set\n",
    "assert isinstance (huff.inverse_transform(test), list), \"Output is supposed to be a list!\"\n",
    "assert len(texts_tst)==len(huff.inverse_transform(test)),\"Output size does not match the input size!\"\n",
    "for i in range(len(huff.inverse_transform(test))):\n",
    "    assert isinstance (huff.inverse_transform(test)[i], bytes),\"Output is supposed to be byte\"\n",
    "assert huff.inverse_transform(test)==texts_tst\n",
    "print(\"correct!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q2 &mdash; Extract features and train a model [30 marks total]\n",
    "\n",
    "This question is a simplified version of the core learning task of the assignent. Specifically, you'll extract features and train a \"next symbol predictor\", but in a way that only requires small, easy, isolated steps, without any fancy software engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2a &mdash; Extract symbol context features [10 marks]*\n",
    "\n",
    "**Implement *extract_text_context*.** For example:\n",
    "```python\n",
    ">>> extract_text_context(b'ABCDEFG', 3)\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'B', b'C', b'D'],\n",
    "       [b'C', b'D', b'E'],\n",
    "       [b'D', b'E', b'F']], dtype='|S1')\n",
    "```\n",
    "Use Numpy effectively in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_context(text: bytes, size):\n",
    "    \"\"\"\n",
    "    Returns an array X representing the ASCII symbol context\n",
    "    that preceeded each byte position of byte string 'text'.\n",
    "    \n",
    "    Specifically, row X[i,:] contains the 'size' symbols that\n",
    "    preceeded the symbol text[i]. If no such symbol existed,\n",
    "    (too close to start) a NULL byte (0) is used in its place.\n",
    "    \"\"\"\n",
    "\n",
    "    t=len(text)\n",
    "    matric=np.empty((t,size),dtype='|S1')\n",
    "    for i in range(t):\n",
    "        for j in range(size):\n",
    "            if i+j-size>=0:\n",
    "                matric[i,j]=bytes([text[i+j-size]])\n",
    "            else:\n",
    "                matric[i,j]=b\"\"\n",
    "    return matric\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'', b'', b''],\n",
       "       [b'', b'', b'A'],\n",
       "       [b'', b'A', b'B'],\n",
       "       [b'A', b'B', b'C'],\n",
       "       [b'B', b'C', b'D'],\n",
       "       [b'C', b'D', b'E'],\n",
       "       [b'D', b'E', b'F']], dtype='|S1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=b'ABCDEFG'\n",
    "extract_text_context(b'ABCDEFG', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement *extract_context*.** This will be useful for converting a list of *bytes* objects into a feature matrix. For example:\n",
    "```python\n",
    ">>> extract_context([b'ABCD', b'EFG'], 3)\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'', b'', b''],\n",
    "       [b'', b'', b'E'],\n",
    "       [b'', b'E', b'F']], dtype='|S1')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_context(x: list, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a concatenation of all context features extracted\n",
    "    from every text string in the given filedict, in the order\n",
    "    that the text entries appear. Any extra arguments are\n",
    "    forwarded to extract_text_context.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    a=[]\n",
    "    for text in x:\n",
    "             aa= extract_text_context(text,*args)\n",
    "             a.append(aa)\n",
    "    res=np.concatenate(a)\n",
    "    return res \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'', b'', b''],\n",
       "       [b'', b'', b'A'],\n",
       "       [b'', b'A', b'B'],\n",
       "       [b'A', b'B', b'C'],\n",
       "       [b'', b'', b''],\n",
       "       [b'', b'', b'E'],\n",
       "       [b'', b'E', b'F']], dtype='|S1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_context([b'ABCD', b'EFG'],3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement *make_sklearn_dataset*.** This function is just a convenient way to get not just the context features $\\mathbf{X}$ but also corresponding targets $\\mathbf{y}$ for scikit-learn style training or testing.\n",
    "```python\n",
    ">>> X, y = make_sklearn_dataset([b'ABCD', b'EFG'], 3)\n",
    ">>> X\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'', b'', b''],\n",
    "       [b'', b'', b'E'],\n",
    "       [b'', b'E', b'F']], dtype='|S1')\n",
    ">>> y\n",
    "array([b'A', b'B', b'C', b'D', b'E', b'F', b'G'], dtype='|S1')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sklearn_dataset(x: list, *args, **kwargs):\n",
    "    \"\"\"    \n",
    "    Converts a list of bytes objects into arrays X and y suitable\n",
    "    for use as a dataset with a scikit-learn estimator.\n",
    "    \"\"\"\n",
    "    # Your implementation here.\n",
    "    X=extract_context(x, *args, **kwargs)\n",
    "    y_join=b''.join(x)\n",
    "    y = np.frombuffer(y_join, dtype='S1')\n",
    "        \n",
    "    return X,y\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[b'', b'', b''],\n",
       "        [b'', b'', b'A'],\n",
       "        [b'', b'A', b'B'],\n",
       "        [b'A', b'B', b'C'],\n",
       "        [b'', b'', b''],\n",
       "        [b'', b'', b'E'],\n",
       "        [b'', b'E', b'F']], dtype='|S1'),\n",
       " array([b'A', b'B', b'C', b'D', b'E', b'F', b'G'], dtype='|S1'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sklearn_dataset([b'ABCD', b'EFG'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert your training and test sets to arrays.** Use your *make_sklearn_dataset* function to build training and testing arrays. Each feature vector should contain the 5 ASCII symbols preceeding each corresponding target. In future steps we may refer to these arrays as $(\\mathbf{X}_\\text{trn}, \\mathbf{y}_\\text{trn})$ and $(\\mathbf{X}_\\text{tst}, \\mathbf{y}_\\text{tst})$. Your code cell should also **print the first 10 rows of your $\\mathbf{X}_\\text{trn}$ and $\\mathbf{y}_\\text{trn}$ arrays, then $\\mathbf{X}_\\text{tst}$ and $\\mathbf{y}_\\text{tst}$ arrays**, so that the TA can see your raw symbol features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 rows of X_trn:\n",
      " [[b'' b'' b'' b'' b'']\n",
      " [b'' b'' b'' b'' b'\"']\n",
      " [b'' b'' b'' b'\"' b'\"']\n",
      " [b'' b'' b'\"' b'\"' b'\"']\n",
      " [b'' b'\"' b'\"' b'\"' b'K']\n",
      " [b'\"' b'\"' b'\"' b'K' b'e']\n",
      " [b'\"' b'\"' b'K' b'e' b'r']\n",
      " [b'\"' b'K' b'e' b'r' b'n']\n",
      " [b'K' b'e' b'r' b'n' b'e']\n",
      " [b'e' b'r' b'n' b'e' b'l']]\n",
      "first 10 rows of y_trn:\n",
      " [b'\"' b'\"' b'\"' b'K' b'e' b'r' b'n' b'e' b'l' b's']\n",
      "\n",
      " first 10 rows of X_tst:\n",
      " [[b'' b'' b'' b'' b'']\n",
      " [b'' b'' b'' b'' b'\"']\n",
      " [b'' b'' b'' b'\"' b'\"']\n",
      " [b'' b'' b'\"' b'\"' b'\"']\n",
      " [b'' b'\"' b'\"' b'\"' b'\\n']\n",
      " [b'\"' b'\"' b'\"' b'\\n' b'R']\n",
      " [b'\"' b'\"' b'\\n' b'R' b'i']\n",
      " [b'\"' b'\\n' b'R' b'i' b'd']\n",
      " [b'\\n' b'R' b'i' b'd' b'g']\n",
      " [b'R' b'i' b'd' b'g' b'e']]\n",
      "first 10 rows of y_tst:\n",
      " [b'\"' b'\"' b'\"' b'\\n' b'R' b'i' b'd' b'g' b'e' b' ']\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_trn,y_trn =make_sklearn_dataset(texts_trn,5)\n",
    "X_tst,y_tst=make_sklearn_dataset(texts_tst,5)\n",
    "print(\"first 10 rows of X_trn:\\n %s\" %(X_trn[:10]))\n",
    "print(\"first 10 rows of y_trn:\\n %s\" %(y_trn[:10]))\n",
    "print(\"\\n first 10 rows of X_tst:\\n %s\" %(X_tst[:10,:]))\n",
    "print(\"first 10 rows of y_tst:\\n %s\" %(y_tst[:10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2b &mdash; Train a DummyClassifier to predict symbol probabilities  [10 marks]*\n",
    "\n",
    "**Train a *DummyClassifier* on your $\\mathbf{X}_\\text{trn}$ and $\\mathbf{y}_\\text{trn}$ arrays.** Your code should:\n",
    "* Set the *strategy* argument to ensure *predict_proba* counts the frequency of each symbol in target vector $\\mathbf{y}_\\text{trn}$.\n",
    "* Force the *DummyClassifier* to output probabilities for every symbol in *ALPHABET*, not just those appearing in $\\mathbf{y}_\\text{trn}$.\n",
    "\n",
    "Your code cell should print the training and testing accuracy, and the *DummyClassifier*'s number of output classes, as in:\n",
    "```\n",
    "accuracy: trn=0.?????? tst=0.??????\n",
    "nclasses: ?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def add_alphabet(X, y, alphabet: bytes):\n",
    "    \"\"\"\n",
    "    Modify a training set so as to force a scikit-learn classifier\n",
    "    to be capable of outputting every symbol in the given alphabet,\n",
    "    even if those symbols did not appear in 'y'.\n",
    "    \n",
    "    For example:\n",
    "       >>> X_, y_, w_ = add_alphabet(X, y, b'abc')\n",
    "       >>> classifier.fit(X_, y_, sample_weight=w_)\n",
    "    \"\"\"\n",
    "    \n",
    "    if alphabet is None:\n",
    "        return X, y, None\n",
    "    n, m = X.shape[0], len(alphabet)\n",
    "    X_ = X[np.maximum(0, np.arange(-m, n))]  # Works for sparse or dense\n",
    "    y_ = np.concatenate([np.frombuffer(alphabet, 'S1'), y])\n",
    "    w_ = np.concatenate([np.full(m, 1e-100), np.ones(n)])  # 1e-100 rather than 0.0; see https://github.com/scikit-learn/scikit-learn/issues/19654\n",
    "    return X_, y_, w_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: trn=0.2385        tst=0.26025\n",
      "nclasses: [b'' b'\\n' b' ' b'!' b'\"' b'#' b'$' b'%' b'&' b\"'\" b'(' b')' b'*' b'+'\n",
      " b',' b'-' b'.' b'/' b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9'\n",
      " b':' b';' b'<' b'=' b'>' b'?' b'@' b'A' b'B' b'C' b'D' b'E' b'F' b'G'\n",
      " b'H' b'I' b'J' b'K' b'L' b'M' b'N' b'O' b'P' b'Q' b'R' b'S' b'T' b'U'\n",
      " b'V' b'W' b'X' b'Y' b'Z' b'[' b'\\\\' b']' b'^' b'_' b'`' b'a' b'b' b'c'\n",
      " b'd' b'e' b'f' b'g' b'h' b'i' b'j' b'k' b'l' b'm' b'n' b'o' b'p' b'q'\n",
      " b'r' b's' b't' b'u' b'v' b'w' b'x' b'y' b'z' b'{' b'|' b'}' b'~']\n"
     ]
    }
   ],
   "source": [
    "X_,y_,w_=add_alphabet(X_trn, y_trn,ALPHABET)\n",
    "dummy_clf = sklearn.dummy.DummyClassifier(strategy=\"prior\",random_state=0)\n",
    "dummy_clf.fit(X_, y_, sample_weight=w_)\n",
    "acc_trn=dummy_clf.score(X_trn,y_trn)\n",
    "acc_tst=dummy_clf.score(X_tst,y_tst)\n",
    "dum_class=dummy_clf.classes_\n",
    "print(\"Accuracy: trn=%s        tst=%s\" %(acc_trn,acc_tst))\n",
    "print(\"nclasses: %s\"%dum_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Print an example of the *DummyClassifier*'s predictions.** Specifically, print the first 10 training targets in $\\mathbf{y}_\\text{trn}$ alongside the *DummyClassifier*'s predicted symbol. You should convert targets and predictions to *bytes*, so that the output is formatted like:\n",
    "```\n",
    "targets: b'??????????'\n",
    "predict: b'??????????'\n",
    "```\n",
    "where each `?` is replaced by a symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: b'\"\"\"Kernels'\n",
      "predict: b' \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00 \\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print(\"targets: %s\" %bytes(y_trn)[:10])\n",
    "print(\"predict: %s\" %bytes(dummy_clf.predict(X_trn[:10])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to define a helpful function for printing symbols like `a` instead of `b'a'`. Just for readability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', ' ', '\\\\n', '©']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def as_printable(text: bytes):\n",
    "    \"\"\"\n",
    "    Converts each byte into a string suitable for printing and plots,\n",
    "    where most non-printable characters are converted to number strings.\n",
    "\n",
    "    For example:\n",
    "       >>> as_printable(b'ab \\n\\xa9')  # a, b, space, newline (10), copyright (169)\n",
    "       ['a', 'b', ' ', '\\\\n', '©']\n",
    "    \"\"\"\n",
    "    assert isinstance(text, bytes), \"Expected bytes object\"\n",
    "    return [chr(c) if chr(c).isprintable() else '\\\\n' if c == 10 else '\\\\'+str(c) for c in text]\n",
    "\n",
    "as_printable(b'ab \\n\\xa9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the *DummyClassifier*'s symbols and frequencies.** Figure out which attribute of your trained *DummyClassifier* are helpful here. Your cell output should look something like below with the `?` values filled in:\n",
    "```\n",
    "rank  frequency symbol\n",
    "0     0.??????  ?  \n",
    "1     0.??????  ?\n",
    "2     0.??????  ?\n",
    "...\n",
    "?     0.??????  ?\n",
    "```\n",
    "You can apply *as_printable* to the symbols if you like to make the printing nicer, but you do not have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank        frequency        symbol\n",
      "0       3.3333333333333335e-105       []\n",
      "1       3.3333333333333335e-105       ['$']\n",
      "2       3.3333333333333335e-105       ['&']\n",
      "3       3.3333333333333335e-105       ['7']\n",
      "4       3.3333333333333335e-105       ['9']\n",
      "5       3.3333333333333335e-105       [';']\n",
      "6       3.3333333333333335e-105       ['?']\n",
      "7       3.3333333333333335e-105       ['Q']\n",
      "8       3.3333333333333335e-105       ['Z']\n",
      "9       3.3333333333333335e-105       ['^']\n",
      "10       3.3333333333333335e-105       ['|']\n",
      "11       3.3333333333333335e-105       ['~']\n",
      "12       3.3333333333333335e-05       ['J']\n",
      "13       3.3333333333333335e-05       ['U']\n",
      "14       6.666666666666667e-05       ['\\\\']\n",
      "15       0.0001       ['8']\n",
      "16       0.00013333333333333334       ['D']\n",
      "17       0.00016666666666666666       ['6']\n",
      "18       0.0002       ['K']\n",
      "19       0.0002       ['O']\n",
      "20       0.0002       ['W']\n",
      "21       0.00023333333333333333       ['!']\n",
      "22       0.00023333333333333333       ['5']\n",
      "23       0.00023333333333333333       ['Y']\n",
      "24       0.0002666666666666667       ['`']\n",
      "25       0.0003       ['3']\n",
      "26       0.0003       ['F']\n",
      "27       0.0003333333333333333       ['4']\n",
      "28       0.00036666666666666667       ['<']\n",
      "29       0.0004       ['@']\n",
      "30       0.0004       ['H']\n",
      "31       0.0004333333333333333       ['S']\n",
      "32       0.00046666666666666666       ['{']\n",
      "33       0.00046666666666666666       ['}']\n",
      "34       0.0005       ['/']\n",
      "35       0.0005       ['G']\n",
      "36       0.0005       ['j']\n",
      "37       0.0005       ['q']\n",
      "38       0.0005333333333333334       ['B']\n",
      "39       0.0005333333333333334       ['I']\n",
      "40       0.0005333333333333334       ['V']\n",
      "41       0.0006       ['L']\n",
      "42       0.0006       ['M']\n",
      "43       0.0007       ['2']\n",
      "44       0.0008       ['A']\n",
      "45       0.0008       ['N']\n",
      "46       0.0008333333333333334       ['E']\n",
      "47       0.0008666666666666666       ['%']\n",
      "48       0.0009       ['P']\n",
      "49       0.0009666666666666667       ['+']\n",
      "50       0.0012666666666666666       ['R']\n",
      "51       0.0014666666666666667       ['C']\n",
      "52       0.0015       ['z']\n",
      "53       0.0015333333333333334       ['>']\n",
      "54       0.0015666666666666667       ['*']\n",
      "55       0.0017666666666666666       ['0']\n",
      "56       0.002033333333333333       ['T']\n",
      "57       0.0020666666666666667       ['[']\n",
      "58       0.0020666666666666667       [']']\n",
      "59       0.0021333333333333334       ['X']\n",
      "60       0.0022       ['1']\n",
      "61       0.002766666666666667       ['x']\n",
      "62       0.0033       [\"'\"]\n",
      "63       0.004366666666666666       ['b']\n",
      "64       0.005166666666666667       ['w']\n",
      "65       0.0054       ['=']\n",
      "66       0.0056       ['k']\n",
      "67       0.0067666666666666665       ['#']\n",
      "68       0.0067666666666666665       ['v']\n",
      "69       0.007333333333333333       [':']\n",
      "70       0.0084       ['\"']\n",
      "71       0.008433333333333333       ['y']\n",
      "72       0.009333333333333334       [')']\n",
      "73       0.009366666666666667       ['(']\n",
      "74       0.009866666666666666       ['g']\n",
      "75       0.0117       [',']\n",
      "76       0.013533333333333333       ['-']\n",
      "77       0.014333333333333333       ['.']\n",
      "78       0.014833333333333334       ['d']\n",
      "79       0.015366666666666667       ['u']\n",
      "80       0.0172       ['f']\n",
      "81       0.017433333333333332       ['h']\n",
      "82       0.019233333333333335       ['_']\n",
      "83       0.020733333333333333       ['m']\n",
      "84       0.022       ['c']\n",
      "85       0.023666666666666666       ['l']\n",
      "86       0.026766666666666668       ['p']\n",
      "87       0.030166666666666668       ['\\\\n']\n",
      "88       0.034333333333333334       ['o']\n",
      "89       0.0373       ['i']\n",
      "90       0.040933333333333335       ['n']\n",
      "91       0.045       ['t']\n",
      "92       0.04613333333333333       ['r']\n",
      "93       0.0495       ['s']\n",
      "94       0.056       ['a']\n",
      "95       0.07663333333333333       ['e']\n",
      "96       0.2385       [' ']\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "frequency,symbol=zip(*sorted(zip(dummy_clf.class_prior_,dum_class)))\n",
    "print(\"rank\"+\"        \"+\"frequency\"+\"        \"+\"symbol\")\n",
    "for i in range(dummy_clf.n_classes_):\n",
    "    print(str(i)+\"       \"+str(frequency[i])+\"       \"+str(as_printable(symbol[i])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement *plot_symbol_probs.*** This function visualizes the \"next symbol\" probabilities (the class probabilities) and the corresponding true symbols (the targets). When applied to your *DummyClassifier* and training set, your plot should look something like the one below. You will use this plotting function to visualize probabilities and predictions:\n",
    "<img src=\"img/symbol-probs-dummy.png\"/>\n",
    "*Hint:* Try using `colorbar(fraction=0.01, pad=0.01)` or similar to shrink the colorbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_symbol_probs(estimator, X, y, rows=20):\n",
    "    \"\"\"\n",
    "    Plots a heatmap where each row shows two things:\n",
    "      1. a target symbol (shown as y-axis label, and by a white 'x'\n",
    "         in the column corresponding to that symbol)\n",
    "      2. the estimator's class probabilities when trying to predict\n",
    "         that symbol from context X (classes shown on x-axis labels).\n",
    "    The max number of rows (true next symbols) shown is given by 'rows'.\n",
    "    \"\"\"\n",
    "    assert sklearn.base.is_classifier(estimator)\n",
    "    # Your implementation here\n",
    "    predicts=estimator.predict_proba(X[:rows])\n",
    "    plt.figure(figsize=(25, 5))\n",
    "    plt.yticks(ticks=np.arange(rows),labels=as_printable(bytes(y_trn[:rows])),rotation=270,fontsize=16)\n",
    "    plt.xticks(ticks=np.arange(len(ALPHABET)),labels=as_printable(ALPHABET),fontsize=16)\n",
    "    plt.imshow( estimator.predict_proba(X[:rows]), cmap='jet', data=as_printable(bytes(y[:rows])),aspect='auto')\n",
    "    plt.colorbar(fraction=0.01, pad=0.01,label=\"probability\")\n",
    "    tmp =as_printable(ALPHABET)\n",
    "    tmp_y = [tmp.index(i.decode()) if i.decode() in tmp else tmp.index('\\\\'+ str(i.decode())) for i in y[:rows]]\n",
    "    plt.scatter(tmp_y, range(len(tmp_y)) , marker='x', color='w')\n",
    "    \n",
    "    plt.xlabel('possible next symbol')\n",
    "    plt.ylabel('true next symbol')\n",
    "    plt.title(\"probability of next symbol(DummyClassifier)\",size=20)\n",
    "\n",
    "\n",
    "# Call your implementation on your trained DummyClassifier here\n",
    "plot_symbol_probs(dummy_clf, X_trn,y_trn,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Complete the following sentence: \"My *DummyClassifier* will correctly predict the 'next symbol' if...\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If frequency is high or in the other words, entropy is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q2c &mdash; Train a DecisionTreeClassifier to predict symbol probabilities [10 marks]*\n",
    "\n",
    "Most scikit-learn estimators do not accept ASCII bytes (*dtype='S1'*) as input features. Instead, they expect *dtype=float64*. So, before training your *DecisionTreeClassifier*, you need a way to transform your ASCII feature matrix $\\mathbf{X}_\\text{trn}$ into some numerical representation compatible with scikit-learn estimators. Standard choices are *OrdinalEncoder* and *OneHotEncoder*.\n",
    "\n",
    "**Train an OrdinalEncoder on your $\\mathbf{X}_\\text{trn}$ array.** Your encoder should be able to accept any extended ASCII symbol (any byte) in any feature column. Your code cell should also print the transformed version of the first 10 rows of $\\mathbf{X}_\\text{trn}$. <span style=\"color:red\">Bug alert: If you are using scikit-learn 0.24 it may raise an error when using arrays with *dtype='S'*; see bug and workaround [here](https://github.com/scikit-learn/scikit-learn/issues/19677).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  4.  4.]\n",
      " [ 0.  0.  4.  4.  4.]\n",
      " [ 0.  4.  4.  4. 45.]\n",
      " [ 4.  4.  4. 45. 71.]\n",
      " [ 4.  4. 45. 71. 84.]\n",
      " [ 4. 45. 71. 84. 80.]\n",
      " [45. 71. 84. 80. 71.]\n",
      " [71. 84. 80. 71. 78.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  4.  4.]\n",
      " [ 0.  0.  4.  4.  4.]\n",
      " [ 0.  4.  4.  4.  1.]\n",
      " [ 4.  4.  4.  1. 52.]\n",
      " [ 4.  4.  1. 52. 75.]\n",
      " [ 4.  1. 52. 75. 70.]\n",
      " [ 1. 52. 75. 70. 73.]\n",
      " [52. 75. 70. 73. 71.]]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "batch = np.frombuffer(ALPHABET, dtype='S1')\n",
    "enc = OrdinalEncoder(categories=[batch, batch, batch, batch, batch])\n",
    "enc.fit(X_trn,y_trn)\n",
    "X_trn_transformed=enc.transform(X_trn)\n",
    "X_tst_transformed=enc.transform(X_tst)\n",
    "print(X_trn_transformed[:10,:])\n",
    "print(X_tst_transformed[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a *DecisionTreeClassifier*.** Use default hyperparameters (but always set *random_state*). Your code cell should print the training and testing accuracy:\n",
    "```\n",
    "accuracy: trn=0.?????? tst=0.??????\n",
    "nclasses: ?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: trn=0.8801        tst=0.5687\n",
      "nclasses: [b'' b'\\n' b' ' b'!' b'\"' b'#' b'$' b'%' b'&' b\"'\" b'(' b')' b'*' b'+'\n",
      " b',' b'-' b'.' b'/' b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7' b'8' b'9'\n",
      " b':' b';' b'<' b'=' b'>' b'?' b'@' b'A' b'B' b'C' b'D' b'E' b'F' b'G'\n",
      " b'H' b'I' b'J' b'K' b'L' b'M' b'N' b'O' b'P' b'Q' b'R' b'S' b'T' b'U'\n",
      " b'V' b'W' b'X' b'Y' b'Z' b'[' b'\\\\' b']' b'^' b'_' b'`' b'a' b'b' b'c'\n",
      " b'd' b'e' b'f' b'g' b'h' b'i' b'j' b'k' b'l' b'm' b'n' b'o' b'p' b'q'\n",
      " b'r' b's' b't' b'u' b'v' b'w' b'x' b'y' b'z' b'{' b'|' b'}' b'~']\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_DT,y_DT,w_DT=add_alphabet(X_trn_transformed, y_trn,ALPHABET)\n",
    "clf_DT=sklearn.tree.DecisionTreeClassifier(random_state=0)\n",
    "clf_DT.fit(X_DT,y_DT,w_DT)\n",
    "acc_trn_DT=clf_DT.score(X_trn_transformed,y_trn)\n",
    "acc_tst_DT=clf_DT.score(X_tst_transformed,y_tst)\n",
    "DT_class=clf_DT.classes_\n",
    "print(\"Accuracy: trn=%s        tst=%s\" %(acc_trn_DT,acc_tst_DT))\n",
    "print(\"nclasses: %s\"%DT_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the predicted symbol probabilities.** Use your *plot_symbol_probs* function from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call your plotting function here\n",
    "plot_symbol_probs(clf_DT, X_trn_transformed, y_trn, rows=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows should now have different probabilities, and the \"true next symbol\" should be predicted correctly more often!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q3 &mdash; Use predictions to compress text [25 marks total]\n",
    "\n",
    "This question asks you to use your *DecisionTreeClassifier* from Question 2 to transform a symbol (e.g., `e` or `+`) into the \"rank of that symbol's predicted probability\" (e.g., 0 or 13). The idea is depicted visually at the top of this assignment.\n",
    "\n",
    "The core part of this question will be to define a scikit-learn style trainable pipeline with two top-level steps:\n",
    "1. Rank-encode the symbols using tools you built in Question 2:\n",
    "   * extract context features (e.g., symbols like `['i', 'm', 'p', 'o', 'r']`)\n",
    "   * convert features to numbers (e.g., ordinal encoding like `[73, 77, 80, 79, 82]`)\n",
    "   * predict probability of each possible \"next symbol\" (e.g., like `'t'`) from the context features\n",
    "2. Huffman-encode the ranks using your class from Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3a &mdash; Transform symbols into their predicted rank [5 marks]*\n",
    "\n",
    "**Implement *rankencode*.** \n",
    "\n",
    "```python\n",
    ">>> y = np.frombuffer(b'abcbc', 'S1')   # Symbols to encode\n",
    ">>> c = np.frombuffer(b'abc', 'S1')     # Symbol class for each column of p\n",
    ">>> p = np.array([[.5, .2, .3],         # Predicted symbol probabilities\n",
    "...               [.0, .7, .3],\n",
    "...               [.3, .0, .7],\n",
    "...               [.7, .3, .0],\n",
    "...               [.3, .0, .7]])\n",
    ">>> rankencode(y, c, p)                 # Convert each symbol to a rank\n",
    "array([0, 0, 0, 1, 0], dtype=uint8)\n",
    "\n",
    ">>> y = np.frombuffer(b'abcxyz', 'S1')  # Uh-oh, can't encode symbols 'xyz'!\n",
    ">>> rankencode(y, c, p)\n",
    "ValueError: Not all symbols in y were found in the classes c\n",
    ">>> rankencode(y.astype('S4'), c, p)\n",
    "ValueError: Dtypes of y and c must match\n",
    "```\n",
    "Only a few lines of vectorized code are needed. <span style=\"color:#080;font-weight:bold\">Briefly comment each line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rankencode(y, c, p):\n",
    "    \"\"\"\n",
    "    Returns a rank-encoded version of array y.\n",
    "\n",
    "    y: length-N array to encode.\n",
    "    c: length-M array of symbols in the alphabet.\n",
    "    p: NxM array of probabilities where probs[i,j] is\n",
    "       the probability that input symbol i is going\n",
    "       to match alphabet element j; this is the same\n",
    "       layout scikit-learn's predict_proba function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your implementation here\n",
    "    if type(y) != type(c):\n",
    "        raise ValueError('ValueError: Dtypes of y and c must match')\n",
    "    \n",
    "\n",
    "    if not np.all(np.in1d(y,c)):\n",
    "        raise ValueError ('ValueError: Not all symbols in y were found in the classes c')\n",
    "    \n",
    "        \n",
    "    copy= np.flip(np.argsort(p, axis=1), axis=1)    #sort(ascending format) the predict proba matrice regarding its corresponding index                                      \n",
    "    yv=y.reshape(-1, 1)                             #vectorize the true values(a,b,c,...)\n",
    "    nn, target = np.where(yv==c)                    #Finding the corresponding class of true values (1,2,3,...)\n",
    "    target = target.reshape(-1, 1)                  #vectorize the true values(1,2,3,...)\n",
    "    nn, rank = np.where(copy==target)               #comparing the predicted and true values, where ever they are equal save the index of predicted value\n",
    "    rank=rank.astype('uint8')\n",
    "    \n",
    "    return rank\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = np.frombuffer(b'abcbc', 'S1')   \n",
    "c = np.frombuffer(b'abc', 'S1')     \n",
    "p = np.array([[.5, .2, .3],         \n",
    "              [.0, .7, .3],\n",
    "              [.3, .0, .7],\n",
    "              [.7, .3, .0],\n",
    "              [.3, .0, .7]])\n",
    "\n",
    "\n",
    "rankencode(y, c, p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below. It should reproduce the example from the top of this assignment, encoding *[a,b,c,b,c]* as *[0, 0, 0, 1, 0]*, along with some other sample strings that you can use to verify correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcbc -> [0 0 0 1 0]\n",
      "abcabc -> [0 0 0 0 0 0]\n",
      "cbaacba -> [1 1 1 2 1 1 1]\n",
      "aaa -> [0 2 2]\n",
      "bbb -> [2 2 2]\n",
      "ccc -> [1 2 2]\n"
     ]
    }
   ],
   "source": [
    "class ToyGuesser:\n",
    "    \"\"\"Toy \"guesser\" from the top of the assignment as scikit-learn style class.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classes_ = np.frombuffer(b'abc', 'S1')  # Mimick sklearn classes_ attribute\n",
    "        \n",
    "    def predict_proba(self, text: bytes):\n",
    "        p = dict(zip(b'\\0abc', [[.5, .2, .3], [.0, .7, .3], [.3, .0, .7], [.7, .3, .0]]))\n",
    "        return np.array([p[c] for c in (b'\\0' + text[:-1])])  # unvectorized for simplicity\n",
    "\n",
    "toy = ToyGuesser()\n",
    "for text in [b'abcbc', b'abcabc', b'cbaacba', b'aaa', b'bbb', b'ccc']:\n",
    "    print(text.decode('ascii'), '->',\n",
    "          rankencode(np.frombuffer(text, 'S1'), toy.classes_, toy.predict_proba(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3b &mdash; Measure the entropy of your rank-encoded datasets [2 marks]*\n",
    "\n",
    "\n",
    "**Rank-encode the first 20 rows your $\\mathbf{X}_\\text{trn}$ and $\\mathbf{X}_\\text{trn}$ arrays.** Use your *DummyClassifier* and (separately) your *DecisionTreeClassifier* from Question 2. Your code cell should print something like this, but with the `?` replaced by integers:\n",
    "```\n",
    "train:\n",
    "  dummy: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "  dtree: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "test:\n",
    "  dummy: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "  dtree: [ ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      " dummy:[26 26 26 76  1  4  6  1 11  3  0 16  8  4  0 59  2 17  3  3]\n",
      " tree:[0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 4 0 0 0 0]\n",
      "\n",
      "test:\n",
      " dummy:[26 26 26  9 46  7 18 22  1  0  4  1 22  4  1  3  3  7  8  6]\n",
      " tree:[ 0  0  0  0 78 52 86 62 73 28 51  0  0 61  0  0  0  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "#Tree\n",
    "clf_DT=sklearn.tree.DecisionTreeClassifier(random_state=0)\n",
    "clf_DT.fit(X_DT,y_DT,w_DT)\n",
    "DT_class=clf_DT.classes_\n",
    "p1=clf_DT.predict_proba(X_trn_transformed)\n",
    "p2=clf_DT.predict_proba(X_tst_transformed)\n",
    "tree_trn_re=rankencode(y_trn,DT_class,p1)\n",
    "tree_tst_re=rankencode(y_tst,DT_class,p2)\n",
    "\n",
    "\n",
    "#Dummy\n",
    "X_,y_,w_=add_alphabet(X_trn, y_trn,ALPHABET)\n",
    "dummy_clf = sklearn.dummy.DummyClassifier(strategy=\"prior\",random_state=0)\n",
    "dummy_clf.fit(X_, y_, sample_weight=w_)\n",
    "dum_class=dummy_clf.classes_\n",
    "p3=dummy_clf.predict_proba(X_trn)\n",
    "p4=dummy_clf.predict_proba(X_tst)\n",
    "dum_trn_re=rankencode(y_trn,dum_class,p3)\n",
    "dum_tst_re=rankencode(y_tst,dum_class,p4)\n",
    "\n",
    "\n",
    "\n",
    "print(\"train:\\n dummy:%s\\n tree:%s\\n\"%(dum_trn_re[:20],tree_trn_re[:20]))\n",
    "\n",
    "print(\"test:\\n dummy:%s\\n tree:%s\\n\"%(dum_tst_re[:20],tree_tst_re[:20]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the entropy of different encodings.** Print the entropy (in bits) of your $\\mathbf{y}_\\text{trn}$ and $\\mathbf{y}_\\text{tst}$ arrays using three encodings:\n",
    "1. *ascii:* the raw symbol arrays with no rank encoding applied,\n",
    "2. *dummy:* rank encoding with your *DummyClassifier* from Question 2, and\n",
    "3. *dtree:* rank encoding with your *DecisionTreeClassifier* from Question 2.\n",
    "\n",
    "Your code cell should print output like the following, where 1.0000 would indicate 1 bit of entropy.\n",
    "```\n",
    "ascii: trn=?.???? tst=?.????\n",
    "dummy: trn=?.???? tst=?.????\n",
    "dtree: trn=?.???? tst=?.????\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii:trn=4.58250377825611       tst=4.591155838484329\n",
      "dummy:trn=4.58250377825611       tst=4.591155838484329\n",
      "dtree:trn=0.8407865000137059       tst=3.4304947444617517\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "def print_entropy(freqs):\n",
    "    return scipy.stats.entropy(freqs, base=2)\n",
    "    \n",
    "freqs_trn=list(Counter(y_trn).values())\n",
    "freqs_tst=list(Counter(y_tst).values())\n",
    "freqs_trn_tree=list(Counter(tree_trn_re).values())\n",
    "freqs_trn_dum=list(Counter(dum_trn_re).values())\n",
    "freqs_tst_tree=list(Counter(tree_tst_re).values())\n",
    "freqs_tst_dum=list(Counter(dum_tst_re).values())\n",
    "print('ascii:trn=%s       tst=%s'%(print_entropy(freqs_trn),print_entropy(freqs_tst)))\n",
    "print('dummy:trn=%s       tst=%s'%(print_entropy(freqs_trn_dum),print_entropy(freqs_tst_dum)))\n",
    "print('dtree:trn=%s       tst=%s'%(print_entropy(freqs_trn_tree),print_entropy(freqs_tst_tree)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Why is the entropy of *DummyClassifier*'s rank encoding no different than the original ASCII encoding?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because dummy classifier rank encode based on random selection of classes (\"prior strategy\" using class prior) regardless of the features, it is similar to ASCII when no rank encoding is applied to the features and prediction performed only regarding the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Why is the entropy of *DecisionTreeClassifier*'s rank encoding different on the training set than on the test set?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Becuase the Descion tree object was fit on X_DT,y_DT,w_DT obtained from the add_alphabet function which originally gives higher weights to train dataset, that means there can be some data in test dataset which doesn not show up in train data set leading to lower weight to correspondong unseen data. That leads to higher numbers resulting from rankencode function and ultimately higher entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3c &mdash; Define a scikit-learn style feature extractor [6 marks]*\n",
    "\n",
    "This question takes things you already know how to do and asks you to start putting them together in a scikit-learn style class. It is essentially a \"machine learning software engineering\" exercise.\n",
    "\n",
    "\n",
    "**Define an *ExtractContext* transformer class.** This feature-extraction class should do two things:\n",
    "1. wrap your *extract_context* function from *Q2a* in a scikit-learn style transformer; and\n",
    "2. allow the resulting ASCII byte features to be transformed into numbers like you did in *Q2c*\n",
    "\n",
    "Your implementation should behave as depicted below:\n",
    "\n",
    "```python\n",
    ">>> x = [b'ABCD', b'EFG']\n",
    ">>> z = [b'FOO']\n",
    ">>> ctx = ExtractContext(size=3)\n",
    ">>> ctx.fit_transform(x)   # Extracts ASCII features for all text in x\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'A'],\n",
    "       [b'', b'A', b'B'],\n",
    "       [b'A', b'B', b'C'],\n",
    "       [b'', b'', b''],\n",
    "       [b'', b'', b'E'],\n",
    "       [b'', b'E', b'F']], dtype='|S1')\n",
    ">>> ctx.transform(z)       # All columns can handle any extended ASCII symbol\n",
    "array([[b'', b'', b''],\n",
    "       [b'', b'', b'F'],\n",
    "       [b'', b'F', b'O']], dtype='|S1')\n",
    "```\n",
    "And it should support a custom 'encoder' to transform the ASCII symbols into some numeric representation. The encoder shoould be configured to work with any input symbol:\n",
    "```python\n",
    ">>> enc = OrdinalEncoder()\n",
    ">>> ctx = ExtractContext(encoder=enc)\n",
    ">>> ctx.fit_transform(x)     # ASCII symbols now get fed through an encoder\n",
    "array([[ 0.,  0.,  0.],\n",
    "       [ 0.,  0., 32.],\n",
    "       [ 0., 32., 33.],\n",
    "       [32., 33., 34.],\n",
    "       [ 0.,  0.,  0.],\n",
    "       [ 0.,  0., 36.],\n",
    "       [ 0., 36., 37.]])\n",
    ">>> ctx.transform([b'FOO'])  # All columns still handle any symbol\n",
    "array([[ 0.,  0.,  0.],\n",
    "       [ 0.,  0., 37.],\n",
    "       [ 0., 37., 46.]])\n",
    ">>> enc.categories           # The original \"enc\" object is not fitted...\n",
    "'auto'\n",
    ">>> ctx.encoder_.categories  # ...by sklearn convention, a clone is fitted\n",
    "[array([b'', b'\\n', b' ', b'!', ...), ...]\n",
    "       \n",
    "```\n",
    "And of course the usual sanity checking:\n",
    "```python\n",
    ">>> ExtractContext(3)        # By sklearn convention, only keyword args allowed\n",
    "TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ">>> ctx = ExtractContext()\n",
    ">>> ctx.transform(x)\n",
    "NotFittedError: This ExtractContext instance is not fitted yet.\n",
    ">>> ctx.fit(b'ABC')          # Should accept textlist to transform\n",
    "ValueError: Expected list of bytes objects\n",
    ">>> ctx.fit(x, y=[1,2,3])    # Should not accept separate training targets\n",
    "ValueError: Expected None\n",
    "```\n",
    "\n",
    "<span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0., 40.],\n",
       "       [ 0., 40., 49.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your class definition here and anything else supporting it\n",
    "\n",
    "class ExtractContext(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, size=3, encoder=None):\n",
    "        \n",
    "        self.size = size\n",
    "        self.batch = np.frombuffer(ALPHABET, dtype='S1')\n",
    "        self.encoder = encoder\n",
    "        self.extracted = None\n",
    "        self.categories_ = None\n",
    "        \n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        if y is not None:\n",
    "            raise ValueError('Expected None')\n",
    "        if self.encoder is None:\n",
    "            self.extracted = extract_context(x, self.size)\n",
    "            return self\n",
    "        else:\n",
    "            self.encoder_ = self.encoder\n",
    "            self.encoder_.set_params(categories=[self.batch]*self.size)\n",
    "\n",
    "            self.extracted = extract_context(x, self.size)\n",
    "            self.encoder_.fit(self.extracted)\n",
    "            self.categories_=self.encoder.categories_[0]\n",
    "            self.encoder = sklearn.base.clone(self.encoder_)\n",
    "            return self\n",
    "            \n",
    "    def transform(self, x, y=None):\n",
    "        if self.encoder is None:\n",
    "            self.extracted = extract_context(x, self.size)\n",
    "            return self.extracted\n",
    "        else:\n",
    "            check_is_fitted(self, 'encoder')\n",
    "            self.extracted = extract_context(x, self.size)\n",
    "            return self.encoder_.transform(self.extracted)\n",
    "        \n",
    "    def fit_transform(self, x, y=None):\n",
    "#         self.fit(x)\n",
    "        return self.fit(x).transform(x)\n",
    "\n",
    "\n",
    "x = [b'ABCD', b'EFG']\n",
    "z = [b'FOO']\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "ctx = ExtractContext(encoder=enc)\n",
    "ctx.fit_transform(x)\n",
    "ctx.transform(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your class definition here and anything else supporting it\n",
    "def check_is_none(y):\n",
    "    if y is not None:\n",
    "        raise ValueError(\"Expected None\")\n",
    "        \n",
    "def check_is_List(X):\n",
    "    if not isinstance(X, list):\n",
    "        raise ValueError(\"Expected list of bytes objects\")\n",
    "        \n",
    "class ExtractContext(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, size=3, encoder=None):\n",
    "        self.size = size\n",
    "        self.encoder = encoder\n",
    "        self.extracted = None\n",
    "        if encoder is not None:\n",
    "            batch = np.frombuffer(ALPHABET, dtype='S1')\n",
    "            self.batch=batch\n",
    "         \n",
    "       \n",
    "        \n",
    "    def fit(self, X,y=None):\n",
    "        check_is_List(X)\n",
    "        check_is_none(y)\n",
    "        self.is_fitted_=True\n",
    "        \n",
    "        if self.encoder is None:\n",
    "            ASCII  = extract_context(X, self.size)\n",
    "            self.ASCII =ASCII \n",
    "        else:\n",
    "            self.encoder_ = self.encoder\n",
    "            self.encoder_.set_params(categories=[self.batch]*self.size) #All coloumns are forced to recognised all characters in ALPHABET\n",
    "            self.ASCII  = extract_context(X, self.size)\n",
    "            self.encoder_.fit(self.ASCII )\n",
    "            self.encoder = sklearn.base.clone(self.encoder_)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X,y=None):\n",
    "        check_is_none(y)\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        ASCII = extract_context(X, self.size)\n",
    "        if self.encoder is not None:\n",
    "            ASCII=self.encoder_.transform(ASCII)\n",
    "        return ASCII\n",
    "\n",
    "        \n",
    "    def fit_transform(self, X,y=None):\n",
    "        check_is_none(y)\n",
    "        \n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'', b'', b''],\n",
       "       [b'', b'', b'A'],\n",
       "       [b'', b'A', b'B'],\n",
       "       [b'A', b'B', b'C'],\n",
       "       [b'', b'', b''],\n",
       "       [b'', b'', b'E'],\n",
       "       [b'', b'E', b'F']], dtype='|S1')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "x = [b'ABCD', b'EFG']\n",
    "z = [b'FOO']\n",
    "ctx = ExtractContext()\n",
    "ctx.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'', b'', b''],\n",
       "       [b'', b'', b'F'],\n",
       "       [b'', b'F', b'O']], dtype='|S1')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.transform(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0., 35.],\n",
       "       [ 0., 35., 36.],\n",
       "       [35., 36., 37.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0., 39.],\n",
       "       [ 0., 39., 40.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "x = [b'ABCD', b'EFG']\n",
    "z = [b'FOO']\n",
    "ctx = ExtractContext(encoder=enc)\n",
    "ctx.fit(x).transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0., 40.],\n",
       "       [ 0., 40., 49.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.transform(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3c &mdash; Define a scikit-learn style rank encoder [8 marks]*\n",
    "\n",
    "\n",
    "**Define a *RankEncoder* transformer class.** This class should be designed similarly to *HuffmanEncoder* from Question 1. However, *RankEncoder* is only responsible for rank-encoding the text list passed in, not actually compressing them. It should explcitly take two arguments:\n",
    "* *estimator:* an instance of the kind of classifier to use for predicting the next symbol, analogous to how the *base_estimator* parameter of [*BaggingClassifier*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) is used. The default should be a *DummyClassifier*.\n",
    "* *extractor:* a feature extractor to convert a filedict object into featre vectors that *estimator* accepts. For example, if *estimator* is a *DecisionTreeClassifier*, then *extractor* must transform a text list into an array $\\mathbf{X}$ of numbers, not ASCII bytes.\n",
    "\n",
    "For example of expected behaviour:\n",
    "```python\n",
    ">>> x = [b'HELLO', b'THERE']\n",
    ">>> rank = RankEncoder(extractor=ExtractContext(size=3, encoder=OrdinalEncoder()),\n",
    "...                    estimator=DecisionTreeClassifier(random_state=0, max_depth=3))\n",
    ">>> rank.fit_transform(x)              # Fit extractor and estimator to x\n",
    "[b'\\x00\\x00\\x00\\x00\\x00', b'\\x01\\x00\\x01\\x00\\x01']\n",
    ">>> rank.transform([b'FOO'])           # Handle symbol in ALPHABET even if not trained\n",
    "[b'\\x11//']\n",
    ">>> rank.estimator_.classes_\n",
    "array([b'', b'\\x01', b'\\x02', ...])\n",
    ">>> rank.estimator_ is rank.estimator  # By sklearn convention, estimator_ is clone\n",
    "False\n",
    "```\n",
    "If no *extractor* and *estimator* prototypes are specified, defaults should be created:\n",
    "```python\n",
    ">>> rank = RankEncoder()\n",
    ">>> rank.fit_transform(x)              # DummyClassifier encodes E=0, L=1, H=2, etc\n",
    "[b'\\x02\\x00\\x01\\x01\\x03', b'\\x05\\x02\\x00\\x04\\x00']\n",
    ">>> rank.extractor, rank.estimator     # No value was given for these...\n",
    "(None, None)\n",
    ">>> rank.extractor_, rank.estimator_   # ...so defaults get created on fit\n",
    "(ExtractContext(), DummyClassifier(strategy='prior'))\n",
    "```\n",
    "And as usual do sanity checking and try to adhere to sklearn conventions:\n",
    "```python\n",
    ">>> RankEncoder(ExtractContext())      # Require keyword args (sklearn convention)\n",
    "TypeError: __init__() takes 1 positional argument but 2 were given\n",
    ">>> RankEncoder().transform(x)\n",
    "NotFittedError: This RankEncoder instance is not fitted yet.\n",
    "```\n",
    "\n",
    "You do *not* need to implement an *inverse_transform* (rank decode) method, although it is one way to sanity-check your code.\n",
    "\n",
    "<span style=\"color:#080;font-weight:bold\">Briefly comment each non-trivial line of your code.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your class definition here and anything else supporting it\n",
    "class RankEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,extractor=ExtractContext(size=3, encoder=OrdinalEncoder()),\n",
    "                      estimator=sklearn.dummy.DummyClassifier(strategy=\"prior\")):\n",
    "        self.extractor= extractor\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        self.extractor_=self.extractor\n",
    "        self.estimator_=sklearn.base.clone(self.estimator, safe=True) #rank.estimator_ is not rank.estimator\n",
    "        \n",
    "        _y=np.frombuffer(b\"\".join(X), dtype='S1')\n",
    "        ex=self.extractor_.fit(X).transform(X)\n",
    "        self.ex=ex\n",
    "        self._y=_y\n",
    "        X_re,y_re,w_re=add_alphabet(ex,_y,ALPHABET)                  #To force all ALPHABET\n",
    "        self.estimator_.fit(X_re,y_re,w_re)\n",
    "        \n",
    "        self.is_fitted_=True\n",
    "          \n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        \n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        _y=np.frombuffer(b\"\".join(X), dtype='S1')\n",
    "        \n",
    "        members=len(X)\n",
    "        member_length=[]\n",
    "        for i in range(members):\n",
    "            m_length=len(X[i])\n",
    "            member_length.append(m_length)\n",
    "        \n",
    "        \n",
    "        w=[]                                     #Detect the length of each member an iterate on them\n",
    "        i=0\n",
    "        for j in member_length:\n",
    "            r=rankencode(_y[i:j+i],self.estimator_.classes_,self.estimator_.predict_proba(self.ex[i:j+i]))\n",
    "            i=i+j\n",
    "            g=r.tobytes()\n",
    "            w.append(g) \n",
    "\n",
    "            \n",
    "        return w\n",
    "    \n",
    "    def fit_transform(self,X,y=None):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X,y)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Write a few lines of code** to demonstrate to the TA that your *RankEncoder* implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\\x01\\x00\\x02\\x02\\x03', b'\\x05\\x01\\x00\\x04\\x00']\n",
      "[b'\\x14\\x03\\x03']\n",
      "[b'\\x00\\x00\\x00\\x00\\x00', b'\\x01\\x00\\x01\\x00\\x01']\n",
      "[b'\\x1222']\n"
     ]
    }
   ],
   "source": [
    "# Your sanity-checking code here.\n",
    "x = [b'HELLO', b'THERE']  \n",
    "\n",
    "rank=RankEncoder()\n",
    "print(rank.fit(x).transform(x))\n",
    "print(rank.transform([b'FOO']))\n",
    "\n",
    "rank = RankEncoder(extractor=ExtractContext(size=3, encoder=OrdinalEncoder()),\n",
    "                    estimator=sklearn.tree.DecisionTreeClassifier(random_state=0, max_depth=3))\n",
    "print(rank.fit(x).transform(x))\n",
    "print(rank.transform([b'FOO']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q3d &mdash; Pipeline your RankEncoder and HuffmanEncoder together [4 marks]*\n",
    "\n",
    "**Create a scikit-learn *Pipeline* and train it.** Your [*Pipeline*](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) object (a [composite estimator](https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators)) should transform a list of uncompressed bytes objects (texts) into a list of compressed bytes objects (Huffman codes), like this:\n",
    "```python\n",
    ">>> compress = Pipeline([...])\n",
    ">>> compress.fit_transform([b'abcabc', b'abc'])  # Fits and transforms each stage\n",
    "[b'\\xfd', b'\\xe8']\n",
    ">>> compress.transform([b'bca', b'zzz'])         # Handle any symbol in ALPHABET\n",
    "[b' \\xd0', b'\\n\\n\\n']\n",
    "```\n",
    "\n",
    "The rank-encoding step should be configured to extract 3 context symbols, encoded as ordinals, and fed into a *DecisionTreeClassifier* having *random_state=0*. Fit the pipeline to your training set. *Hint:* Think about what your *HuffmanEncoder*'s alphabet should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\\xfd', b'\\xe8']\n",
      "[b'\\x1c\\x1d\\x1c', b'\\x04\\x04\\x04']\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "from sklearn.pipeline import make_pipeline\n",
    "compress=make_pipeline(RankEncoder(extractor=ExtractContext(size=3, encoder=OrdinalEncoder()),\n",
    "                    estimator=sklearn.tree.DecisionTreeClassifier(random_state=0, max_depth=3)),\n",
    "                                   HuffmanEncoder(range(len(ALPHABET))))\n",
    "\n",
    "print(compress.fit_transform([b'abcabc', b'abc']))\n",
    "print(compress.transform([b'bca', b'zzz']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display your pipeline as a diagram.** Use [*sklearn.set_config*](https://scikit-learn.org/stable/modules/generated/sklearn.set_config.html) to display your pipeline as an interactive diagram, like below.\n",
    "\n",
    "<img src=\"img/pipeline-diagram.png\" width=300px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2f3180ff-359e-443f-8b77-99ef0cb83d96\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2f3180ff-359e-443f-8b77-99ef0cb83d96\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('rankencoder',\n",
       "                 RankEncoder(estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                              random_state=0))),\n",
       "                ('huffmanencoder', HuffmanEncoder(alphabet=range(0, 97)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"96811a78-cdbe-44c6-9319-30f86501a161\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"96811a78-cdbe-44c6-9319-30f86501a161\">rankencoder: RankEncoder</label><div class=\"sk-toggleable__content\"><pre>RankEncoder(estimator=DecisionTreeClassifier(max_depth=3, random_state=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1c0b7835-d310-4172-b0da-d95f9116cc11\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1c0b7835-d310-4172-b0da-d95f9116cc11\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bf13f1c1-ab9f-4c20-a94d-33f906413b62\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"bf13f1c1-ab9f-4c20-a94d-33f906413b62\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[array([b'', b'\\n', b' ', b'!', b'\"', b'#', b'$', b'%', b'&', b\"'\", b'(',\n",
       "       b')', b'*', b'+', b',', b'-', b'.', b'/', b'0', b'1', b'2', b'3',\n",
       "       b'4', b'5', b'6', b'7', b'8', b'9', b':', b';', b'<', b'=', b'>',\n",
       "       b'?', b'@', b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I',\n",
       "       b'J', b'K', b'L', b'M', b'N', b'O', b'P', b'Q', b'R', b'S', b'T',\n",
       "       b'U', b'V', b'W', b'X', b'Y', b'Z', b'[', b'\\\\', b...\n",
       "       b'4', b'5', b'6', b'7', b'8', b'9', b':', b';', b'<', b'=', b'>',\n",
       "       b'?', b'@', b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I',\n",
       "       b'J', b'K', b'L', b'M', b'N', b'O', b'P', b'Q', b'R', b'S', b'T',\n",
       "       b'U', b'V', b'W', b'X', b'Y', b'Z', b'[', b'\\\\', b']', b'^', b'_',\n",
       "       b'`', b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j',\n",
       "       b'k', b'l', b'm', b'n', b'o', b'p', b'q', b'r', b's', b't', b'u',\n",
       "       b'v', b'w', b'x', b'y', b'z', b'{', b'|', b'}', b'~'], dtype='|S1')])</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"38e5e2e0-0acc-45fa-8a11-b9b38b5738ae\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"38e5e2e0-0acc-45fa-8a11-b9b38b5738ae\">HuffmanEncoder</label><div class=\"sk-toggleable__content\"><pre>HuffmanEncoder(alphabet=range(0, 97))</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('rankencoder',\n",
       "                 RankEncoder(estimator=DecisionTreeClassifier(max_depth=3,\n",
       "                                                              random_state=0))),\n",
       "                ('huffmanencoder', HuffmanEncoder(alphabet=range(0, 97)))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here (couple of lines)\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "compress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print compression ratios of your pipeline.** Use your *Pipline* object to print the compression ratios of your training and testing texts, much like you did for just the *HuffmanEncoder* in Question 1. (Remember that when you ask a *Pipeline* object to score some input, it will call the *score* method of the last object in the pipeline.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:1.8401521192418573\n",
      "Test score:1.5855398763278896\n"
     ]
    }
   ],
   "source": [
    "# Print the compression ratios of your training and testing textlists here\n",
    "compress.fit_transform(texts_trn)\n",
    "compress.transform(texts_trn)\n",
    "print(\"Train score:%s\"%compress.score(texts_trn))\n",
    "print(\"Test score:%s\"%compress.score(texts_tst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q4 &mdash; Maximize the compression rate [30 marks total]\n",
    "\n",
    "This question challenges you to maximize the compression on held-out test data. To do so, you'll need to try swapping different scikit-learn estimators into your \"compression pipeline\" and then optimizing their hyperparameters.\n",
    "\n",
    "Before you get started, it's important to inspect the hyperparameters of your basic decision-tree compression pipeline from Question 3. **Edit and run the code cell below** to print the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "rankencoder\n",
      "huffmanencoder\n",
      "rankencoder__estimator__ccp_alpha\n",
      "rankencoder__estimator__class_weight\n",
      "rankencoder__estimator__criterion\n",
      "rankencoder__estimator__max_depth\n",
      "rankencoder__estimator__max_features\n",
      "rankencoder__estimator__max_leaf_nodes\n",
      "rankencoder__estimator__min_impurity_decrease\n",
      "rankencoder__estimator__min_impurity_split\n",
      "rankencoder__estimator__min_samples_leaf\n",
      "rankencoder__estimator__min_samples_split\n",
      "rankencoder__estimator__min_weight_fraction_leaf\n",
      "rankencoder__estimator__presort\n",
      "rankencoder__estimator__random_state\n",
      "rankencoder__estimator__splitter\n",
      "rankencoder__estimator\n",
      "rankencoder__extractor__encoder__categories\n",
      "rankencoder__extractor__encoder__dtype\n",
      "rankencoder__extractor__encoder\n",
      "rankencoder__extractor__size\n",
      "rankencoder__extractor\n",
      "huffmanencoder__alphabet\n"
     ]
    }
   ],
   "source": [
    "def print_param_names(estimator):\n",
    "    for name in estimator.get_params():  # get_params() returns a dict, so iterate keys\n",
    "        print(name)\n",
    "    \n",
    "print_param_names(compress) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take special note of the kinds of parameters that you might like to \"tune\" to maximize compression:\n",
    "* `...__extractor`, the object wholly responsible for feature extraction;\n",
    "* `...__extractor__size`, an *ExtractContext*-specific hyperparameter dictating the context size;\n",
    "* `...__extractor__encoder`, the object (if any) responsible for transforming ASCII context features into numbers\n",
    "* `...__estimator`, the classifier responsible for predicting \"next-symbol probabilities\" from the features\n",
    "* `...__estimator__max_depth`, a tree-specific hyperparameter that would not exist for other *estimator* types.\n",
    "* and more, depending on which feature extraction pipeline and classifier you use\n",
    "\n",
    "Scikit-learn's *get_params* method is provided by [*BaseEstimator*](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html). It automatically discovers all [nested parameters](https://scikit-learn.org/stable/modules/compose.html#nested-parameters). This makes it possible to override parameters by name during a hyperparameter search, such as [*GridSearchCV*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) or [*RandomizedSearchCV*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "In fact you can try replacing the prototype *estimator* attribute (not to be confused with the fitted *estimator_* attribute) with something completely different, like a [*LogisticRegression*](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), and the list of hyperparameters at your disposal will change!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are ready, use the code cell below to define any utility functions that simplify your remaining code cells, to make those code cells as concise as possible. Ideas for useful stuff (optional!):\n",
    "* import whatever you need that isn't already imported yet;\n",
    "* function to save/load results that took a long time to compute;\n",
    "* function to make sorting and displaying results as a pandas *DataFrame* convenient;\n",
    "* function to run hyperparameter search with whatever defaults you currently want (*verbose*, *n_jobs*, *refit*, etc.);\n",
    "* function to strip down the items of textlist, to make a \"mini\" training set for faster experimentation on initial hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your utility functions here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "\n",
    "def gridsearch(X,params, n_jobs=-1, refit=True, cv=3,verbose=2):\n",
    "    GS=GridSearchCV(X, params, n_jobs=n_jobs, refit=refit, cv=cv,verbose=verbose)\n",
    "    return GS.fit(texts_trn)\n",
    "\n",
    "def save_hyper(X,y:str):\n",
    "    return dump(X,y)\n",
    "\n",
    "def data_frame(X):\n",
    "    df = pd.DataFrame({'mean_test_score':X.cv_results_['mean_test_score'], \n",
    "                'std_test_score':X.cv_results_['std_test_score'],\n",
    "                'rank_test_score':X.cv_results_['rank_test_score']})\n",
    "\n",
    "    df.sort_values(by=['mean_test_score'], ascending=False, inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4a &mdash; Maximize compression with a DecisionTreeClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *DecisionTreeClassifier* estimator.** There are two requirements:\n",
    "1. Once the search is complete, you must save the search object, e.g., `a1q4-dtree.joblib`; see the scikit-learn documentation on [how to save objects](https://scikit-learn.org/stable/modules/model_persistence.html) to pickle files efficiently using *joblib*. <span style=\"color:red\">The pickle file should be submitted as part of your assignment, as a pre-trained model.</span>\n",
    "2. Running your code cell must also result in the results of the hyperparameter search being displayed as a *pandas* *DataFrame* object, sorted to show the best cross-validation scores first (the *mean_test_score* column). For example, if the TA scrolls through the columns they should see most of the hyperparameter settings for each trial and the *test_score* columns should look something like this:\n",
    "\n",
    "<img src=\"img/search-dataframe-example.png\" width=280/>\n",
    "\n",
    "Some tips:\n",
    "* Since your training set is a list of 3 files, use 3-fold cross validation so that each file gets a turn being \"held out\".\n",
    "* *RandomizedSearchCV* gives easier control over total training time (number of samples) than *GridSearchCV* does. (If you use the faster \"*Halving*\" CV types to explore settings, do not submit your assignment with them: they are new and not yet available in the version of sklearn used in this course.)\n",
    "* The CV search's *n_jobs* parameter is a powerful way to speed things up, using all your CPU cores.\n",
    "* Keep a variable that remembers the search object, or save it to disk, since you'll need it for a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:   56.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.686336</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.686336</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686336</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.686336</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.672455</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.672455</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.672455</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.672455</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.626424</td>\n",
       "      <td>0.022674</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.626424</td>\n",
       "      <td>0.022674</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.626424</td>\n",
       "      <td>0.022674</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.626424</td>\n",
       "      <td>0.022674</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.611739</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.611739</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.611739</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.611739</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.535542</td>\n",
       "      <td>0.038260</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.532794</td>\n",
       "      <td>0.036461</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.520703</td>\n",
       "      <td>0.033214</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.518402</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.518010</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.515497</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.515055</td>\n",
       "      <td>0.043127</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.514883</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.513054</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.503233</td>\n",
       "      <td>0.037185</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.497985</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.497985</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.496419</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.492282</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.489178</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.489178</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.480433</td>\n",
       "      <td>0.028906</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.415829</td>\n",
       "      <td>0.041677</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.415008</td>\n",
       "      <td>0.033522</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.415008</td>\n",
       "      <td>0.033522</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.412812</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.412428</td>\n",
       "      <td>0.030834</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.408122</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.391224</td>\n",
       "      <td>0.038541</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.382139</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.379143</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.377872</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.377687</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.360293</td>\n",
       "      <td>0.008864</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.357762</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.357212</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.354571</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  rank_test_score\n",
       "0          1.686336        0.017676                1\n",
       "1          1.686336        0.017676                1\n",
       "2          1.686336        0.017676                1\n",
       "3          1.686336        0.017676                1\n",
       "27         1.672455        0.028779                5\n",
       "26         1.672455        0.028779                5\n",
       "25         1.672455        0.028779                5\n",
       "24         1.672455        0.028779                5\n",
       "7          1.626424        0.022674                9\n",
       "4          1.626424        0.022674                9\n",
       "5          1.626424        0.022674                9\n",
       "6          1.626424        0.022674                9\n",
       "28         1.611739        0.025294               13\n",
       "31         1.611739        0.025294               13\n",
       "30         1.611739        0.025294               13\n",
       "29         1.611739        0.025294               13\n",
       "47         1.535542        0.038260               17\n",
       "23         1.532794        0.036461               18\n",
       "43         1.520703        0.033214               19\n",
       "11         1.518402        0.012705               20\n",
       "10         1.518010        0.012236               21\n",
       "46         1.515497        0.042837               22\n",
       "22         1.515055        0.043127               23\n",
       "9          1.514883        0.013102               24\n",
       "8          1.513054        0.013343               25\n",
       "42         1.503233        0.037185               26\n",
       "35         1.497985        0.003399               27\n",
       "34         1.497985        0.003399               27\n",
       "33         1.496419        0.003913               29\n",
       "32         1.492282        0.007880               30\n",
       "45         1.489178        0.031033               31\n",
       "21         1.489178        0.031033               31\n",
       "41         1.480433        0.028906               33\n",
       "18         1.415829        0.041677               34\n",
       "44         1.415008        0.033522               35\n",
       "20         1.415008        0.033522               35\n",
       "19         1.412812        0.033493               37\n",
       "40         1.412428        0.030834               38\n",
       "17         1.408122        0.030664               39\n",
       "16         1.391224        0.038541               40\n",
       "12         1.382139        0.006717               41\n",
       "13         1.379143        0.005635               42\n",
       "15         1.377872        0.005043               43\n",
       "14         1.377687        0.005701               44\n",
       "36         1.360293        0.008864               45\n",
       "39         1.357762        0.008291               46\n",
       "38         1.357212        0.008472               47\n",
       "37         1.354571        0.007957               48"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "params_DT= {'rankencoder__estimator':[DecisionTreeClassifier(random_state=0)],\n",
    "            'rankencoder__extractor__size':np.linspace(3,12,4,dtype=np.int16), 'rankencoder__estimator__max_depth':np.logspace(0,5,6,base=2,dtype=np.int16),\n",
    "            'rankencoder__estimator__criterion':[\"gini\",\"entropy\"]}\n",
    "GS_DT=gridsearch(X=compress , params=params_DT)\n",
    "save_hyper(GS_DT, 'a1q4-DT.joblib')\n",
    "data_frame(GS_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4b &mdash; Maximize compression with a RandomForestClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *RandomForestClassifier* estimator.** Again, your code cell should also (1) save the search object and (2) display a *DataFrame* of results like for *Q4a*.\n",
    "\n",
    "Some new tips:\n",
    "* If you want the hyperparameter search to replace your default estimator (*DecisionTreeClassifier*) with a different type, you can add an entry like this in your hyperparameter search space:\n",
    "\n",
    "```python\n",
    "    '...__estimator': [RandomForestClassifier(random_state=0)],\n",
    "```\n",
    "\n",
    "* *RandomForestClassifier* takes a lot longer to train than *DecisionTreeClassifier*, so you will not be able to try as many hyperparameter settings in a reasonable time. That is OK, it can still perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:   41.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.725753</td>\n",
       "      <td>0.046279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.725069</td>\n",
       "      <td>0.042475</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.724782</td>\n",
       "      <td>0.044697</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.724383</td>\n",
       "      <td>0.044654</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.723786</td>\n",
       "      <td>0.046499</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.723228</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.723221</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.722617</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.722607</td>\n",
       "      <td>0.044695</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.722330</td>\n",
       "      <td>0.045089</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.722067</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.721190</td>\n",
       "      <td>0.043993</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.721049</td>\n",
       "      <td>0.045103</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.721003</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.720060</td>\n",
       "      <td>0.044982</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.719318</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.718520</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.710995</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.673517</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.668118</td>\n",
       "      <td>0.040940</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.667373</td>\n",
       "      <td>0.038881</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.653664</td>\n",
       "      <td>0.041928</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.653163</td>\n",
       "      <td>0.039050</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.652081</td>\n",
       "      <td>0.041159</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.647023</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.645110</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.642690</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.637242</td>\n",
       "      <td>0.028537</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.628603</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.626757</td>\n",
       "      <td>0.030456</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.625035</td>\n",
       "      <td>0.033776</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.624242</td>\n",
       "      <td>0.029068</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.618836</td>\n",
       "      <td>0.029711</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.618739</td>\n",
       "      <td>0.031783</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.614996</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.610331</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.610031</td>\n",
       "      <td>0.028608</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.603541</td>\n",
       "      <td>0.027420</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.603018</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.601355</td>\n",
       "      <td>0.035106</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.597429</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.592505</td>\n",
       "      <td>0.025446</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.587881</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.587744</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.582103</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.574169</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.573253</td>\n",
       "      <td>0.023540</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.568727</td>\n",
       "      <td>0.026053</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.566115</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.560823</td>\n",
       "      <td>0.017362</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.558061</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.549987</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.544442</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.540023</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  rank_test_score\n",
       "2          1.725753        0.046279                1\n",
       "1          1.725069        0.042475                2\n",
       "0          1.724782        0.044697                3\n",
       "5          1.724383        0.044654                4\n",
       "7          1.723786        0.046499                5\n",
       "4          1.723228        0.043299                6\n",
       "29         1.723221        0.045101                7\n",
       "6          1.722617        0.044898                8\n",
       "3          1.722607        0.044695                9\n",
       "8          1.722330        0.045089               10\n",
       "27         1.722067        0.043774               11\n",
       "32         1.721190        0.043993               12\n",
       "34         1.721049        0.045103               13\n",
       "30         1.721003        0.044135               14\n",
       "28         1.720060        0.044982               15\n",
       "33         1.719318        0.043948               16\n",
       "35         1.718520        0.043748               17\n",
       "31         1.710995        0.049147               18\n",
       "11         1.673517        0.044906               19\n",
       "14         1.668118        0.040940               20\n",
       "17         1.667373        0.038881               21\n",
       "41         1.653664        0.041928               22\n",
       "44         1.653163        0.039050               23\n",
       "15         1.652081        0.041159               24\n",
       "10         1.647023        0.022318               25\n",
       "38         1.645110        0.039091               26\n",
       "13         1.642690        0.025247               27\n",
       "16         1.637242        0.028537               28\n",
       "42         1.628603        0.034826               29\n",
       "37         1.626757        0.030456               30\n",
       "12         1.625035        0.033776               31\n",
       "9          1.624242        0.029068               32\n",
       "43         1.618836        0.029711               33\n",
       "40         1.618739        0.031783               34\n",
       "39         1.614996        0.033936               35\n",
       "26         1.610331        0.027283               36\n",
       "23         1.610031        0.028608               37\n",
       "25         1.603541        0.027420               38\n",
       "36         1.603018        0.029593               39\n",
       "20         1.601355        0.035106               40\n",
       "24         1.597429        0.019669               41\n",
       "53         1.592505        0.025446               42\n",
       "50         1.587881        0.025692               43\n",
       "22         1.587744        0.020961               44\n",
       "21         1.582103        0.015889               45\n",
       "18         1.574169        0.013150               46\n",
       "19         1.573253        0.023540               47\n",
       "47         1.568727        0.026053               48\n",
       "52         1.566115        0.020717               49\n",
       "51         1.560823        0.017362               50\n",
       "49         1.558061        0.020460               51\n",
       "48         1.549987        0.015823               52\n",
       "46         1.544442        0.007937               53\n",
       "45         1.540023        0.014739               54"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "params_RF= {'rankencoder__estimator':[RandomForestClassifier(random_state=0)],\n",
    "            'rankencoder__extractor__size':[3,5,8], 'rankencoder__estimator__max_depth':[1,3,5],\n",
    "            'rankencoder__estimator__criterion':[\"gini\",\"entropy\"],\n",
    "            'rankencoder__estimator__n_estimators':np.logspace(2,4,3,base=2,dtype=np.int16)}\n",
    "GS_RF=gridsearch(X=compress , params=params_RF)\n",
    "save_hyper(GS_RF, 'a1q4-RF.joblib')\n",
    "data_frame(GS_RF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4c &mdash; Maximize compression with a LogisticRegression [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *LogisticRegression* estimator.** Again, your code cell should also (1) save the search object and (2) display a *DataFrame* of results like for *Q4a*.\n",
    "\n",
    "Some new tips:\n",
    "\n",
    "* Since *LogisticRegression* supports sparse feature matrices, your search should include both *OrdinalEncoder* and *OneHotEncoder* as choices for the context features. Check the results to see which representation works best.\n",
    "* *LogisticRegression* can still take a very long time to train. The `sag` solver tends to scale a bit better. You can choose to limit the number of training steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.8min finished\n",
      "C:\\Users\\pgyaf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.593654</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.593654</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.593654</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.593651</td>\n",
       "      <td>0.026815</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.593570</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.569832</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.520008</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.477328</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.450820</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.433352</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score  rank_test_score\n",
       "4         1.593654        0.026888                1\n",
       "6         1.593654        0.026888                1\n",
       "8         1.593654        0.026888                1\n",
       "0         1.593651        0.026815                4\n",
       "2         1.593570        0.026905                5\n",
       "1         1.569832        0.014695                6\n",
       "3         1.520008        0.005566                7\n",
       "5         1.477328        0.002634                8\n",
       "7         1.450820        0.001836                9\n",
       "9         1.433352        0.002133               10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "params_LR= {'rankencoder__estimator':[LogisticRegression(random_state=0,solver='sag')],\n",
    "            'rankencoder__estimator__C' : np.logspace(-1,1,5),\n",
    "            'rankencoder__extractor__encoder':[OrdinalEncoder(),OneHotEncoder()]}\n",
    "GS_LR=gridsearch(X=compress , params=params_LR)\n",
    "save_hyper(GS_LR, 'a1q4-LR.joblib')\n",
    "data_frame(GS_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4d &mdash; Maximize compression with a AdaBoostClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with an *AdaBoostClassifier*.** Again, your code cell should also (1) save the search object and (2) display a *DataFrame* of results like for *Q4a*. Be sure to also consider setting adjusting hyperparameters of the *base_estimator* used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.616964</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.587990</td>\n",
       "      <td>0.030786</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.582713</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.577645</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.569344</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.555161</td>\n",
       "      <td>0.017319</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.515126</td>\n",
       "      <td>0.052518</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.500749</td>\n",
       "      <td>0.028232</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.494218</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.493679</td>\n",
       "      <td>0.026538</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.493679</td>\n",
       "      <td>0.026538</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.490167</td>\n",
       "      <td>0.061162</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.489648</td>\n",
       "      <td>0.039388</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.485218</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.470754</td>\n",
       "      <td>0.025971</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.470695</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.458226</td>\n",
       "      <td>0.017791</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.444176</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  rank_test_score\n",
       "2          1.616964        0.063624                1\n",
       "4          1.587990        0.030786                2\n",
       "1          1.582713        0.030701                3\n",
       "5          1.577645        0.026485                4\n",
       "0          1.569344        0.024613                5\n",
       "3          1.555161        0.017319                6\n",
       "10         1.515126        0.052518                7\n",
       "16         1.500749        0.028232                8\n",
       "17         1.494218        0.008256                9\n",
       "12         1.493679        0.026538               10\n",
       "15         1.493679        0.026538               10\n",
       "7          1.490167        0.061162               12\n",
       "13         1.489648        0.039388               13\n",
       "14         1.485218        0.014603               14\n",
       "8          1.470754        0.025971               15\n",
       "11         1.470695        0.019269               16\n",
       "9          1.458226        0.017791               17\n",
       "6          1.444176        0.009546               18"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "params_AB= {'rankencoder__estimator':[AdaBoostClassifier(sklearn.tree.DecisionTreeClassifier(),random_state=0)],\n",
    "            'rankencoder__extractor__size':[3,5,8], \n",
    "            'rankencoder__estimator__base_estimator__max_depth':[1,3,5],\n",
    "            'rankencoder__estimator__n_estimators': np.logspace(5,6,2,base=2,dtype=np.int16)}\n",
    "\n",
    "GS_AB=gridsearch(X=compress , params=params_AB)\n",
    "save_hyper(GS_AB, 'a1q4-AB.joblib')\n",
    "data_frame(GS_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4e &mdash; Maximize compression with a HistGradientBoostingClassifier [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with a *HistGradientBoostingClassifier*.** *HistGradientBoostingClassifier* is scikit-learn's implementation of gradient boosting that is inspired by speedups implemented in the popular [*LightGBM*](https://lightgbm.readthedocs.io/en/latest/) software library. It typically trains faster than *GradientBoostingClassifier*, but is based on the same idea. Again, your code cell should also (1) save the search object and (2) display a *DataFrame* of results like for *Q4a*.\n",
    "\n",
    "Some tips:\n",
    "\n",
    "* Note that this classifier is still considered \"experimental\". See its scikit-learn documentation for how to enable importing an experimental estimator.\n",
    "* If you receive an error about, may need to disable \"early stopping\" so that the estimator does not try to further split the training data internally. See the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.664986</td>\n",
       "      <td>0.105154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.639530</td>\n",
       "      <td>0.117689</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.636371</td>\n",
       "      <td>0.080272</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.634280</td>\n",
       "      <td>0.049593</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.629175</td>\n",
       "      <td>0.086148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.629087</td>\n",
       "      <td>0.100023</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.614431</td>\n",
       "      <td>0.057952</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.609985</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.608398</td>\n",
       "      <td>0.056876</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.605422</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.605422</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.603054</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.602826</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.590998</td>\n",
       "      <td>0.041909</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.588738</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.587493</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.587319</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.587319</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.583636</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.581494</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.581494</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.570256</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.569594</td>\n",
       "      <td>0.029487</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.568758</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.566569</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.563424</td>\n",
       "      <td>0.025960</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.560057</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  rank_test_score\n",
       "23         1.664986        0.105154                1\n",
       "10         1.639530        0.117689                2\n",
       "24         1.636371        0.080272                3\n",
       "17         1.634280        0.049593                4\n",
       "22         1.629175        0.086148                5\n",
       "26         1.629087        0.100023                6\n",
       "20         1.614431        0.057952                7\n",
       "2          1.609985        0.035645                8\n",
       "15         1.608398        0.056876                9\n",
       "5          1.605422        0.024398               10\n",
       "8          1.605422        0.024398               10\n",
       "21         1.603054        0.015392               12\n",
       "14         1.602826        0.060547               13\n",
       "11         1.590998        0.041909               14\n",
       "25         1.588738        0.012095               15\n",
       "0          1.587493        0.020921               16\n",
       "6          1.587319        0.020697               17\n",
       "3          1.587319        0.020697               17\n",
       "1          1.583636        0.020804               19\n",
       "7          1.581494        0.021800               20\n",
       "4          1.581494        0.021800               20\n",
       "12         1.570256        0.010398               22\n",
       "16         1.569594        0.029487               23\n",
       "19         1.568758        0.026678               24\n",
       "18         1.566569        0.010557               25\n",
       "9          1.563424        0.025960               26\n",
       "13         1.560057        0.031762               27"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "params_HisB= {'rankencoder__estimator':[HistGradientBoostingClassifier(random_state=0)],\n",
    "            'rankencoder__extractor__size':[3,5,8],\n",
    "            'rankencoder__estimator__max_depth':[1,3,5],    \n",
    "            'rankencoder__estimator__min_samples_leaf':np.linspace(20,60,3,dtype=np.int16),\n",
    "            'rankencoder__estimator__early_stopping':[False]}\n",
    "GS_HisB=gridsearch(X=compress , params=params_HisB)\n",
    "save_hyper(GS_HisB, 'a1q4-HisB.joblib')\n",
    "data_frame(GS_HisB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4f &mdash; Maximize compression with an SVC [4 marks]*\n",
    "\n",
    "**Run hyperparameter search with an *SVC*.** Again, your code cell should also (1) save the search object and (2) display a *DataFrame* of results like for *Q4a*.\n",
    "\n",
    "Some new tips:\n",
    "\n",
    "* Training an SVM to predict many classes is extremely slow (one-vs-rest). Depending on how powerful your computer is, you may need to limit the number of  training examples and/or the SVC's training iterations.\n",
    "* Remember that your rank encoder ultimately needs *predict_proba*. This is not enabled by default on *SVC* classifiers, because it takes extra time to 'calibrate'. Check the *SVC* documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:  4.3min remaining: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:  7.1min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.582035</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.572988</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.560659</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.553884</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.553447</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.546420</td>\n",
       "      <td>0.006572</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score  rank_test_score\n",
       "0         1.582035        0.011988                1\n",
       "3         1.572988        0.011515                2\n",
       "1         1.560659        0.006631                3\n",
       "2         1.553884        0.008231                4\n",
       "4         1.553447        0.003665                5\n",
       "5         1.546420        0.006572                6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "params_SVC= {'rankencoder__estimator':[SVC(random_state=0)],\n",
    "            'rankencoder__extractor__size':[3,5,8],\n",
    "             'rankencoder__estimator__C':np.linspace(1,3,2,dtype=np.int16),\n",
    "            'rankencoder__estimator__kernel':['rbf'],\n",
    "            'rankencoder__estimator__probability':[True]}\n",
    "GS_SVC=gridsearch(X=compress , params=params_SVC)\n",
    "save_hyper(GS_SVC, 'a1q4-SVC.joblib')\n",
    "data_frame(GS_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid black;\"></div>\n",
    "\n",
    "### *Q4g &mdash; Compare the success of hyperparameter search [6 marks]*\n",
    "\n",
    "The idea here is to generate a plot that answers the following question:\n",
    "\n",
    "<img src=\"img/tortoise_and_hare.jpg\" style=\"float:right;margin:5px\" width=150/>\n",
    "\n",
    "> If each hyperparameter is chosen sequentially, and takes a certain amount of time to cross-validate, what would be the best score \"so far\" for each classifier at any given point in time? Do some classifiers \"win the short race\" but others \"win the long race\", like the Tortoise and the Hare?\n",
    "\n",
    "Use the appropriate entries from the *cv_results_* arrays for each search you did. If you ran your jobs in parallel, then you should still compute cumulative times as if they were run serially. Your plot should look something like the one below, where an example *DecisionTreeClassifier* and *RandomForestClassifier* curve are given as a guide. However, the curves and even the peak scores will vary depending on how you performed your hyperparameter search, so you do not need to reproduce the curves below.\n",
    "\n",
    "<img src=\"img/search-curves-example.png\" width=450/>\n",
    "\n",
    "If you did not complete all of Q4a-Q4f then that is OK, just make a plot showing the classifiers that you did manage to train.\n",
    "\n",
    "**Load your saved search objects from Q4a-Q4f.** This is so that the TA can reproduce your plot without having to wait for your Q4a-Q4f to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to load the pre-fitted search objects here\n",
    "DT_obj=load(\"a1q4-DT.joblib\").cv_results_\n",
    "RF_obj=load(\"a1q4-RF.joblib\").cv_results_\n",
    "LR_obj=load(\"a1q4-LR.joblib\").cv_results_\n",
    "AB_obj=load(\"a1q4-AB.joblib\").cv_results_\n",
    "HisB_obj=load(\"a1q4-HisB.joblib\").cv_results_\n",
    "SVC_obj=load(\"a1q4-SVC.joblib\").cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the best cross-validation score found over CPU time.** Use the search objects that you loaded from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Decision Tree\n",
    "plt.figure(figsize=(8,6))\n",
    "df = pd.DataFrame({'mean_test_score': DT_obj['mean_test_score'],'mean_fit_time': DT_obj['mean_fit_time']})\n",
    "df.sort_values(by=['mean_test_score'], inplace=True)\n",
    "time_sum = []\n",
    "time=0\n",
    "for t in df['mean_fit_time']:\n",
    "    time =time+ t\n",
    "    time_sum.append(time)\n",
    "\n",
    "plt.plot(time_sum, df['mean_test_score'], label=\"Decision Tree\")\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "df = pd.DataFrame({'mean_test_score': RF_obj['mean_test_score'],'mean_fit_time':RF_obj['mean_fit_time']})\n",
    "df.sort_values(by=['mean_test_score'], inplace=True)\n",
    "time_sum = []\n",
    "time=0\n",
    "for t in df['mean_fit_time']:\n",
    "    time =time+ t\n",
    "    time_sum.append(time)\n",
    "plt.plot(time_sum, df['mean_test_score'], label=\"Random Forest\")\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "df = pd.DataFrame({'mean_test_score': LR_obj['mean_test_score'],'mean_fit_time':LR_obj['mean_fit_time']})\n",
    "df.sort_values(by=['mean_test_score'], inplace=True)\n",
    "time_sum = []\n",
    "time=0\n",
    "for t in df['mean_fit_time']:\n",
    "    time =time+ t\n",
    "    time_sum.append(time)\n",
    "plt.plot(time_sum, df['mean_test_score'], label=\"LogisticRegression\")\n",
    "         \n",
    "         \n",
    "\n",
    " #AdaBoost   \n",
    "df = pd.DataFrame({'mean_test_score': AB_obj['mean_test_score'],'mean_fit_time':AB_obj['mean_fit_time']})\n",
    "df.sort_values(by=['mean_test_score'], inplace=True)\n",
    "time_sum = []\n",
    "time=0\n",
    "for t in df['mean_fit_time']:\n",
    "    time =time+ t\n",
    "    time_sum.append(time)\n",
    "plt.plot(time_sum, df['mean_test_score'], label=\"AdaBoost\")\n",
    "\n",
    "         \n",
    "         \n",
    "#HisGradBoost\n",
    "df = pd.DataFrame({'mean_test_score': HisB_obj['mean_test_score'],'mean_fit_time':HisB_obj['mean_fit_time']})\n",
    "df.sort_values(by=['mean_test_score'], inplace=True)\n",
    "time_sum = []\n",
    "time=0\n",
    "for t in df['mean_fit_time']:\n",
    "    time =time+ t\n",
    "    time_sum.append(time)\n",
    "plt.plot(time_sum, df['mean_test_score'], label=\"HistGradBoost\")\n",
    "\n",
    "\n",
    "#SVM\n",
    "df = pd.DataFrame({'mean_test_score': SVC_obj['mean_test_score'],'mean_fit_time':SVC_obj['mean_fit_time']})\n",
    "df.sort_values(by=['mean_test_score'], inplace=True)\n",
    "time_sum = []\n",
    "time=0\n",
    "for t in df['mean_fit_time']:\n",
    "    time =time+ t\n",
    "    time_sum.append(time)\n",
    "plt.plot(time_sum, df['mean_test_score'], label=\"SVM\")\n",
    "\n",
    "# plt.plot(time_sum, df['mean_test_score'], label=\"Dummy\")\n",
    "\n",
    "plt.title('max-cross-validation score vs cumulative CPU time')\n",
    "plt.xlabel('seconds')\n",
    "plt.ylabel('compression ratio')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** Based on *YOUR* plot:\n",
    "* If the \"short race\" was a 5 minute compute budget, which classifier(s) would win?\n",
    "* If the \"long race\" was the longest budget you trained for, which classifier(s) would win?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest, Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the compression ratios on training and testing data.** Use the pipeline that had best cross-validation compression ratio for each type of classifier. Also print the total time it took to score each pipeline. Your output should look something like this:\n",
    "```\n",
    "dummy: trn=?.???? tst=?.???? time=?.??? sec\n",
    "dtree: trn=?.???? tst=?.???? time=?.??? sec\n",
    "rf:    trn=?.???? tst=?.???? time=?.??? sec\n",
    "lr:    trn=?.???? tst=?.???? time=?.??? sec\n",
    "ab:    trn=?.???? tst=?.???? time=?.??? sec\n",
    "hgb:   trn=?.???? tst=?.???? time=?.??? sec\n",
    "svm:   trn=?.???? tst=?.???? time=?.??? sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy:   trn=1.7783046828689981     tst=1.6554920950252463    time=0.05422187348206838    sec\n",
      "dtree:   trn=1.7783046828689981     tst=1.6554920950252463    time=0.05422187348206838    sec\n",
      "rf:      trn=1.763979537837361     tst=1.7213185299939753    time=0.3332920221634854    sec\n",
      "lr:      trn=1.819505094614265     tst=1.5810276679841897    time=0.2293999671936035    sec\n",
      "hgb:     trn=1.650346572780284     tst=1.6074586079408455    time=3.638910484902653    sec\n",
      "svm:     trn=1.9845207382417147     tst=1.5835312747426762    time=41.477226535479225    sec\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print(\"dummy:   trn=%s     tst=%s    time=%s    sec\"%(load(\"a1q4-DT.joblib\").score(texts_trn),load(\"a1q4-DT.joblib\").score(texts_tst),np.mean(DT_obj['mean_score_time'])))\n",
    "print(\"dtree:   trn=%s     tst=%s    time=%s    sec\"%(load(\"a1q4-DT.joblib\").score(texts_trn),load(\"a1q4-DT.joblib\").score(texts_tst),np.mean(DT_obj['mean_score_time'])))\n",
    "print(\"rf:      trn=%s     tst=%s    time=%s    sec\"%(load(\"a1q4-RF.joblib\").score(texts_trn),load(\"a1q4-RF.joblib\").score(texts_tst),np.mean(RF_obj['mean_score_time'])))\n",
    "print(\"lr:      trn=%s     tst=%s    time=%s    sec\"%(load(\"a1q4-LR.joblib\").score(texts_trn),load(\"a1q4-LR.joblib\").score(texts_tst),np.mean(LR_obj['mean_score_time'])))\n",
    "print(\"hgb:     trn=%s     tst=%s    time=%s    sec\"%(load(\"a1q4-HisB.joblib\").score(texts_trn),load(\"a1q4-HisB.joblib\").score(texts_tst),np.mean(HisB_obj['mean_score_time'])))\n",
    "print(\"svm:     trn=%s     tst=%s    time=%s    sec\"%(load(\"a1q4-SVC.joblib\").score(texts_trn),load(\"a1q4-SVC.joblib\").score(texts_tst),np.mean(SVC_obj['mean_score_time'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** \n",
    "* Which classifier do you think would be most useful in a real command-line compression tool? Why?\n",
    "* Which classifier would be the least useful in a command-line compression tool? Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random Forest,Because its compression ration is higher in shorter period\n",
    "SVM (After Dummy), Because its trainig time is longer with minimum compression ratio increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# Q5 (BONUS) &mdash; Compress MORE!!! [5 marks]\n",
    "\n",
    "<table><tr><td><img src=\"img/more1.png\" width=300/></td><td><img src=\"img/more2.png\" width=300/></td></tr></table>\n",
    "\n",
    "Up until now you've used relatively small training sets, involving only a handful of (truncated) files. You probably also found that the best hyperparameters do not use of very much \"context\", and so the predictions are primitive.\n",
    "\n",
    "For this bonus question, you should **\"go all out\" maximizing the compression ratio**, even more than you did so in Q4. \n",
    "\n",
    "Specifically, here are the requirements:\n",
    "1. **Python packages.** You cannot rely on new Python packages. Only scikit-learn and its dependencies. \n",
    "2. **Training data.** You can train on any Python file from the scikit-learn 0.24.1 source code. (It is too large to train on all of it, so choose some files.)\n",
    "3. **Estimators.** You can only use built-in scikit-learn estimators, alone or in combination. You *can* use estimators that were not yet convered in the assignment, however.\n",
    "4. **New features.** You are encouraged to introduce new hand-engineered features alongside the context features. See [*FeatureUnion*](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) for example. \n",
    "5. **Features from classical compression algorithms not allowed.** A caveat to #4: new features should be based on the semantic meaning of symbols or words, like whether previous symbols were digits, or whether the previous symbols were a particular Python syntax elements (keywords, comments, etc), etc. If you instead try to incorporate classical string compression techniques as your features, then you make the machine learning component trivial and that defeats the purpose of the exercise.\n",
    "\n",
    "**Grading.** Your final tuned compression pipeline should be saved to a file, which the TA will load and run on a separate withheld test set. Your bonus grade will be computed by scaling your rank among all other students who submitted a bonus question. For example, if 23 students completed the bonus question, and your compression ratio was the 3rd-best (21 of 23), then your grade would be 21/23 = 4.57 extra marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your own unique compression pipeline architecture here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter search on your pipeline architecture here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SEARCH_FILE = 'yourname-final.joblib'   # <-- Put your name here\n",
    "# Save your model to FINAL_SEARCH_FILE here. INCLUDE THE FILE WITH YOUR SUBMISSION."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit and run the code cell below** to demonstrate the performance of your final model on your own test set. The TA will replace *FINAL_ZIP* and *FINAL_FILTER* with a withheld test set, not necessarily from scikit-learn's source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines and complete them.\n",
    "\n",
    "# Load a final test set to try compressing\n",
    "#FINAL_ZIP = ...       # The location of a ZIP from which to load test files\n",
    "#FINAL_FILTER = ...    # A filename filter; THE TA WILL REPLACE THIS WITH MYSTERY TEST SET\n",
    "#x_final_names, x_final = read_textfiles(FINAL_ZIP, FINAL_FILTER)\n",
    "\n",
    "# Load and score the search object that performed the Q5 hyperparameter search.\n",
    "#search_final = ...            # Load FINAL_SEARCH_FILE\n",
    "#search_final.score(x_final)   # Return the compression ratio on the test files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
